{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wangxiaochen/anaconda3/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: compiletime version 3.5 of module 'tensorflow.python.framework.fast_tensor_util' does not match runtime version 3.6\n",
      "  return f(*args, **kwds)\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import keras.backend.tensorflow_backend as KTF\n",
    "\n",
    "config = tf.ConfigProto()  \n",
    "config.gpu_options.allow_growth=True   #不全部占满显存, 按需分配\n",
    "session = tf.Session(config=config)\n",
    "\n",
    "# 设置session\n",
    "KTF.set_session(session)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#!/usr/bin/env\n",
    "# coding:utf-8\n",
    "\"\"\"\n",
    "Created on 17/12/14 上午10:03\n",
    "\n",
    "base Info\n",
    "\"\"\"\n",
    "__author__ = 'xiaochenwang94'\n",
    "__version__ = '1.0'\n",
    "\n",
    "import numpy as np\n",
    "from keras import layers\n",
    "from keras import regularizers\n",
    "from keras.layers import Input, Add, Dense, Activation, ZeroPadding2D, BatchNormalization, Flatten, Conv2D, \\\n",
    "    AveragePooling2D, MaxPooling2D, GlobalMaxPooling2D, Merge, concatenate\n",
    "from keras.models import Model, load_model\n",
    "from keras.preprocessing import image\n",
    "from keras.utils import layer_utils\n",
    "from keras.utils.data_utils import get_file\n",
    "from keras.applications.imagenet_utils import preprocess_input\n",
    "# import pydot\n",
    "from IPython.display import SVG\n",
    "from keras.utils.vis_utils import model_to_dot\n",
    "from keras.utils import plot_model\n",
    "from resnets_utils import *\n",
    "from keras.initializers import glorot_uniform\n",
    "import scipy.misc\n",
    "from matplotlib.pyplot import imshow\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "import keras.backend as K\n",
    "\n",
    "K.set_image_data_format('channels_last')\n",
    "K.set_learning_phase(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# GRADED FUNCTION: identity_block\n",
    "\n",
    "# GRADED FUNCTION: identity_block\n",
    "\n",
    "def identity_block(X, f, filters, stage, block):\n",
    "    \"\"\"\n",
    "    Implementation of the identity block as defined in Figure 3\n",
    "\n",
    "    Arguments:\n",
    "    X -- input tensor of shape (m, n_H_prev, n_W_prev, n_C_prev)\n",
    "    f -- integer, specifying the shape of the middle CONV's window for the main path\n",
    "    filters -- python list of integers, defining the number of filters in the CONV layers of the main path\n",
    "    stage -- integer, used to name the layers, depending on their position in the network\n",
    "    block -- string/character, used to name the layers, depending on their position in the network\n",
    "\n",
    "    Returns:\n",
    "    X -- output of the identity block, tensor of shape (n_H, n_W, n_C)\n",
    "    \"\"\"\n",
    "\n",
    "    # defining name basis\n",
    "    conv_name_base = 'res' + str(stage) + block + '_branch'\n",
    "    bn_name_base = 'bn' + str(stage) + block + '_branch'\n",
    "\n",
    "    # Retrieve Filters\n",
    "    F1, F2, F3 = filters\n",
    "\n",
    "    # Save the input value. You'll need this later to add back to the main path.\n",
    "    X_shortcut = X\n",
    "\n",
    "    # First component of main path\n",
    "    X = Conv2D(filters=F1, kernel_size=(1, 1), strides=(1, 1), padding='valid',\n",
    "               kernel_initializer=glorot_uniform(seed=0), kernel_regularizer=regularizers.l2(0.01))(X)\n",
    "    X = BatchNormalization(axis=3)(X)\n",
    "    X = Activation('relu')(X)\n",
    "\n",
    "    ### START CODE HERE ###\n",
    "\n",
    "    # Second component of main path (≈3 lines)\n",
    "    X = Conv2D(filters=F2, kernel_size=(f, f), strides=(1, 1), padding='same',\n",
    "               kernel_initializer=glorot_uniform(seed=0), kernel_regularizer=regularizers.l2(0.01))(X)\n",
    "    X = BatchNormalization(axis=3)(X)\n",
    "    X = Activation('relu')(X)\n",
    "\n",
    "    # Third component of main path (≈2 lines)\n",
    "    X = Conv2D(filters=F3, kernel_size=(1, 1), strides=(1, 1), padding='valid',\n",
    "               kernel_initializer=glorot_uniform(seed=0), kernel_regularizer=regularizers.l2(0.01))(X)\n",
    "    X = BatchNormalization(axis=3)(X)\n",
    "\n",
    "    # Final step: Add shortcut value to main path, and pass it through a RELU activation (≈2 lines)\n",
    "    X = Add()([X, X_shortcut])\n",
    "    X = Activation('relu')(X)\n",
    "\n",
    "    ### END CODE HERE ###\n",
    "\n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# GRADED FUNCTION: convolutional_block\n",
    "\n",
    "# GRADED FUNCTION: convolutional_block\n",
    "\n",
    "def convolutional_block(X, f, filters, stage, block, s=2):\n",
    "    \"\"\"\n",
    "    Implementation of the convolutional block as defined in Figure 4\n",
    "\n",
    "    Arguments:\n",
    "    X -- input tensor of shape (m, n_H_prev, n_W_prev, n_C_prev)\n",
    "    f -- integer, specifying the shape of the middle CONV's window for the main path\n",
    "    filters -- python list of integers, defining the number of filters in the CONV layers of the main path\n",
    "    stage -- integer, used to name the layers, depending on their position in the network\n",
    "    block -- string/character, used to name the layers, depending on their position in the network\n",
    "    s -- Integer, specifying the stride to be used\n",
    "\n",
    "    Returns:\n",
    "    X -- output of the convolutional block, tensor of shape (n_H, n_W, n_C)\n",
    "    \"\"\"\n",
    "\n",
    "    # defining name basis\n",
    "    conv_name_base = 'res' + str(stage) + block + '_branch'\n",
    "    bn_name_base = 'bn' + str(stage) + block + '_branch'\n",
    "\n",
    "    # Retrieve Filters\n",
    "    F1, F2, F3 = filters\n",
    "\n",
    "    # Save the input value\n",
    "    X_shortcut = X\n",
    "\n",
    "    ##### MAIN PATH #####\n",
    "    # First component of main path\n",
    "    X = Conv2D(F1, (1, 1), strides=(s, s), kernel_initializer=glorot_uniform(seed=0),\n",
    "               kernel_regularizer=regularizers.l2(0.01))(X)\n",
    "    X = BatchNormalization(axis=3)(X)\n",
    "    X = Activation('relu')(X)\n",
    "\n",
    "    ### START CODE HERE ###\n",
    "\n",
    "    # Second component of main path (≈3 lines)\n",
    "    X = Conv2D(F2, (f, f), strides=(1, 1), padding='same',\n",
    "               kernel_initializer=glorot_uniform(seed=0), kernel_regularizer=regularizers.l2(0.01))(X)\n",
    "    X = BatchNormalization(axis=3)(X)\n",
    "    X = Activation('relu')(X)\n",
    "\n",
    "    # Third component of main path (≈2 lines)\n",
    "    X = Conv2D(F3, (1, 1), strides=(1, 1), kernel_initializer=glorot_uniform(seed=0),\n",
    "               kernel_regularizer=regularizers.l2(0.01))(X)\n",
    "    X = BatchNormalization(axis=3)(X)\n",
    "\n",
    "    ##### SHORTCUT PATH #### (≈2 lines)\n",
    "    X_shortcut = Conv2D(F3, (1, 1), strides=(s, s),\n",
    "                        kernel_initializer=glorot_uniform(seed=0), kernel_regularizer=regularizers.l2(0.01))(X_shortcut)\n",
    "    X_shortcut = BatchNormalization(axis=3)(X_shortcut)\n",
    "\n",
    "    # Final step: Add shortcut value to main path, and pass it through a RELU activation (≈2 lines)\n",
    "    X = Add()([X, X_shortcut])\n",
    "    X = Activation('relu')(X)\n",
    "\n",
    "    ### END CODE HERE ###\n",
    "\n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# GRADED FUNCTION: ResNet50\n",
    "\n",
    "def ResNet50(input_shape=(64, 64, 3), layer_num=11):\n",
    "    \"\"\"\n",
    "    Implementation of the popular ResNet50 the following architecture:\n",
    "    CONV2D -> BATCHNORM -> RELU -> MAXPOOL -> CONVBLOCK -> IDBLOCK*2 -> CONVBLOCK -> IDBLOCK*3\n",
    "    -> CONVBLOCK -> IDBLOCK*5 -> CONVBLOCK -> IDBLOCK*2 -> AVGPOOL -> TOPLAYER\n",
    "\n",
    "    Arguments:\n",
    "    input_shape -- shape of the images of the dataset\n",
    "    classes -- integer, number of classes\n",
    "\n",
    "    Returns:\n",
    "    model -- a Model() instance in Keras\n",
    "    \"\"\"\n",
    "    classes = 1\n",
    "    # Define the input as a tensor with shape input_shape\n",
    "    X_input = Input(input_shape)\n",
    "\n",
    "    # Zero-Padding\n",
    "    X = ZeroPadding2D((3, 3))(X_input)\n",
    "\n",
    "    # Stage 1\n",
    "    X = Conv2D(64, (7, 7), strides=(1, 1), kernel_initializer=glorot_uniform(seed=0))(X)\n",
    "    X = BatchNormalization(axis=3)(X)\n",
    "    X = Activation('relu')(X)\n",
    "    X = MaxPooling2D((3, 3), strides=(2, 2))(X)\n",
    "\n",
    "    # Stage 2\n",
    "    X = convolutional_block(X, f=3, filters=[64, 64, 256], stage=2, block='a', s=1)\n",
    "    X = identity_block(X, 3, [64, 64, 256], stage=2, block='b')\n",
    "    X = identity_block(X, 3, [64, 64, 256], stage=2, block='c')\n",
    "\n",
    "    if layer_num >= 15:\n",
    "        # Stage 3 (≈4 lines)\n",
    "        X = convolutional_block(X, f=3, filters=[128, 128, 512], stage=3, block='a', s=2)\n",
    "        X = identity_block(X, 3, [128, 128, 512], stage=3, block='b')\n",
    "\n",
    "    if layer_num >= 20:\n",
    "        # Stage 3 (≈4 lines)\n",
    "        X = convolutional_block(X, f=3, filters=[256, 256, 1024], stage=4, block='a', s=2)\n",
    "        X = identity_block(X, 3, [256, 256, 1024], stage=4, block='b')\n",
    "\n",
    "    # if layer_num >= 23:\n",
    "\n",
    "    #         ### START CODE HERE ###\n",
    "\n",
    "    #         # Stage 3 (≈4 lines)\n",
    "    #         X = convolutional_block(X, f = 3, filters = [128, 128, 512], stage = 3, block='a', s = 2)\n",
    "    #         X = identity_block(X, 3, [128, 128, 512], stage=3, block='b')\n",
    "    #         X = identity_block(X, 3, [128, 128, 512], stage=3, block='c')\n",
    "    #         X = identity_block(X, 3, [128, 128, 512], stage=3, block='d')\n",
    "\n",
    "    #     if layer_num >= 41:\n",
    "\n",
    "    #         # Stage 4 (≈6 lines)\n",
    "    #         X = convolutional_block(X, f = 3, filters = [256, 256, 1024], stage = 4, block='a', s = 2)\n",
    "    #         X = identity_block(X, 3, [256, 256, 1024], stage=4, block='b')\n",
    "    #         X = identity_block(X, 3, [256, 256, 1024], stage=4, block='c')\n",
    "    #         X = identity_block(X, 3, [256, 256, 1024], stage=4, block='d')\n",
    "    #         X = identity_block(X, 3, [256, 256, 1024], stage=4, block='e')\n",
    "    #         X = identity_block(X, 3, [256, 256, 1024], stage=4, block='f')\n",
    "\n",
    "    #     if layer_num == 50:\n",
    "    #         # Stage 5 (≈3 lines)\n",
    "    #         X = convolutional_block(X, f = 3, filters = [512, 512, 2048], stage = 5, block='a', s = 2)\n",
    "    #         X = identity_block(X, 3, [512, 512, 2048], stage=5, block='b')\n",
    "    #         X = identity_block(X, 3, [512, 512, 2048], stage=5, block='c')\n",
    "\n",
    "    #     # AVGPOOL (≈1 line). Use \"X = AveragePooling2D(...)(X)\"\n",
    "    #     X = AveragePooling2D((2, 2), name='avg_pool')(X)\n",
    "\n",
    "    ### END CODE HERE ###\n",
    "\n",
    "    # output layer\n",
    "    X = Flatten()(X)\n",
    "    #     X = Dense(classes, activation='softmax', name='fc' + str(classes), kernel_initializer = glorot_uniform(seed=0))(X)\n",
    "    # X = Dense(1, name='fc' + str(classes), kernel_initializer=glorot_uniform(seed=0))(X)\n",
    "\n",
    "    return X, X_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def Three_ResNet(R1, R2, R3, X_inputs):\n",
    "\n",
    "    X = concatenate([R1, R2, R3])\n",
    "    X = Dense(1, name='fc', kernel_initializer=glorot_uniform(seed=0))(X)\n",
    "\n",
    "    # Create model\n",
    "    model = Model(inputs=X_inputs, outputs=X, name='ThreeResNet50')\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wangxiaochen/anaconda3/lib/python3.6/site-packages/sklearn/cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(24331, 81, 33)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.cross_validation import train_test_split\n",
    "stores = np.load('./ResNetData/stores.npy')\n",
    "print(stores.shape)\n",
    "stores = stores.reshape(stores.shape[0], 9, 9,-1)\n",
    "pois = np.load('./ResNetData/pois.npy')\n",
    "pois = pois.reshape(pois.shape[0],9,9,-1)\n",
    "roads = np.load('./ResNetData/roads.npy')\n",
    "roads = roads.reshape(roads.shape[0],9,9,-1)\n",
    "\n",
    "y_data = np.load('./ResNetData/shopPower_y.npy')\n",
    "origin_y = y_data.copy()\n",
    "# data = data.reshape((24331, 9, 9, 52))\n",
    "y_data = y_data/10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler().fit(stores.reshape(stores.shape[0], -1))\n",
    "stores = scaler.transform(stores.reshape(stores.shape[0], -1))\n",
    "stores = stores.reshape(stores.shape[0], 9, 9, -1)\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler().fit(pois.reshape(pois.shape[0], -1))\n",
    "pois = scaler.transform(pois.reshape(pois.shape[0], -1))\n",
    "pois = pois.reshape(pois.shape[0], 9, 9, -1)\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler().fit(roads.reshape(roads.shape[0], -1))\n",
    "roads = scaler.transform(roads.reshape(roads.shape[0], -1))\n",
    "roads = roads.reshape(roads.shape[0], 9, 9, -1)\n",
    "\n",
    "combine = np.concatenate((stores, pois, roads), axis=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def my_loss(y_true,y_pred):\n",
    "    return K.sqrt(K.mean(K.square(y_true - y_pred), axis=-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "seed = 7\n",
    "np.random.seed(seed)\n",
    "kfold = StratifiedKFold(n_splits=5, shuffle=True, random_state=seed)\n",
    "cvscores = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mini_loss = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model10_stores, instore = ResNet50(input_shape=stores.shape[1:])\n",
    "model10_roads, inroad = ResNet50(input_shape=roads.shape[1:])\n",
    "model10_pois, in3poi = ResNet50(input_shape=pois.shape[1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model10_combine = Three_ResNet(model10_stores, model10_roads, model10_pois, [instore, inroad, in3poi])\n",
    "model10_combine.compile(optimizer='adam', loss='mse', metrics=['mse'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/3\n",
      "800/800 [==============================] - 9s 11ms/step - loss: 26.0270 - mean_squared_error: 2.8031 - val_loss: 23.8232 - val_mean_squared_error: 0.8254\n",
      "Epoch 2/3\n",
      "800/800 [==============================] - 9s 11ms/step - loss: 25.4388 - mean_squared_error: 2.6587 - val_loss: 25.8936 - val_mean_squared_error: 3.3439\n",
      "Epoch 3/3\n",
      "800/800 [==============================] - 9s 11ms/step - loss: 25.8626 - mean_squared_error: 3.5361 - val_loss: 26.1188 - val_mean_squared_error: 4.0244\n"
     ]
    }
   ],
   "source": [
    "line = model10_combine.fit([stores[:1000], roads[:1000], pois[:1000]], y_data[:1000], epochs = 3, batch_size = 16, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'loss': [26.027027168273925, 25.438829345703127, 25.862627105712889],\n",
       " 'mean_squared_error': [2.8031145745515822,\n",
       "  2.6586571151018141,\n",
       "  3.5360728573799132],\n",
       " 'val_loss': [23.82317840576172, 25.893581619262694, 26.11878646850586],\n",
       " 'val_mean_squared_error': [0.82536059379577642,\n",
       "  3.3438695907592773,\n",
       "  4.0244360923767086]}"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "line.history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 15569 samples, validate on 3893 samples\n",
      "Epoch 1/5\n",
      "15569/15569 [==============================] - 73s 5ms/step - loss: 26.6913 - mean_squared_error: 3.4850 - val_loss: 19.3628 - val_mean_squared_error: 0.6679\n",
      "Epoch 2/5\n",
      "15569/15569 [==============================] - 64s 4ms/step - loss: 14.6850 - mean_squared_error: 0.6838 - val_loss: 11.9365 - val_mean_squared_error: 2.2206\n",
      "Epoch 3/5\n",
      "15569/15569 [==============================] - 64s 4ms/step - loss: 7.1116 - mean_squared_error: 0.5079 - val_loss: 10.5117 - val_mean_squared_error: 6.4586\n",
      "Epoch 4/5\n",
      "15569/15569 [==============================] - 68s 4ms/step - loss: 3.1950 - mean_squared_error: 0.4347 - val_loss: 11.9302 - val_mean_squared_error: 10.4868\n",
      "Epoch 5/5\n",
      "15569/15569 [==============================] - 69s 4ms/step - loss: 2.2222 - mean_squared_error: 0.5211 - val_loss: 1.9547 - val_mean_squared_error: 1.2275\n",
      "Train on 15569 samples, validate on 3893 samples\n",
      "Epoch 1/5\n",
      "15569/15569 [==============================] - 70s 4ms/step - loss: 0.7785 - mean_squared_error: 0.2821 - val_loss: 1.5329 - val_mean_squared_error: 1.2916\n",
      "Epoch 2/5\n",
      "15569/15569 [==============================] - 70s 5ms/step - loss: 0.9583 - mean_squared_error: 0.3492 - val_loss: 1.7118 - val_mean_squared_error: 1.4859\n",
      "Epoch 3/5\n",
      "15569/15569 [==============================] - 69s 4ms/step - loss: 0.6491 - mean_squared_error: 0.2524 - val_loss: 2.2518 - val_mean_squared_error: 2.0833\n",
      "Epoch 4/5\n",
      "15569/15569 [==============================] - 68s 4ms/step - loss: 0.7188 - mean_squared_error: 0.3278 - val_loss: 0.4550 - val_mean_squared_error: 0.2492\n",
      "Epoch 5/5\n",
      "15569/15569 [==============================] - 68s 4ms/step - loss: 0.4928 - mean_squared_error: 0.2564 - val_loss: 0.4939 - val_mean_squared_error: 0.2490\n",
      "Train on 15569 samples, validate on 3893 samples\n",
      "Epoch 1/5\n",
      "15569/15569 [==============================] - 68s 4ms/step - loss: 0.5668 - mean_squared_error: 0.2636 - val_loss: 0.7372 - val_mean_squared_error: 0.5478\n",
      "Epoch 2/5\n",
      "15569/15569 [==============================] - 69s 4ms/step - loss: 0.4668 - mean_squared_error: 0.1789 - val_loss: 0.2789 - val_mean_squared_error: 0.1669\n",
      "Epoch 3/5\n",
      "15569/15569 [==============================] - 63s 4ms/step - loss: 0.2082 - mean_squared_error: 0.1045 - val_loss: 3.2574 - val_mean_squared_error: 3.1843\n",
      "Epoch 4/5\n",
      "15569/15569 [==============================] - 64s 4ms/step - loss: 0.4020 - mean_squared_error: 0.1325 - val_loss: 0.2173 - val_mean_squared_error: 0.1233\n",
      "Epoch 5/5\n",
      "15569/15569 [==============================] - 66s 4ms/step - loss: 0.1977 - mean_squared_error: 0.0956 - val_loss: 0.1642 - val_mean_squared_error: 0.1188\n",
      "Train on 15569 samples, validate on 3893 samples\n",
      "Epoch 1/5\n",
      "15569/15569 [==============================] - 67s 4ms/step - loss: 0.1210 - mean_squared_error: 0.0699 - val_loss: 0.1777 - val_mean_squared_error: 0.1362\n",
      "Epoch 2/5\n",
      "15569/15569 [==============================] - 67s 4ms/step - loss: 0.0971 - mean_squared_error: 0.0606 - val_loss: 0.3123 - val_mean_squared_error: 0.2709\n",
      "Epoch 3/5\n",
      "15569/15569 [==============================] - 66s 4ms/step - loss: 0.0928 - mean_squared_error: 0.0586 - val_loss: 0.1032 - val_mean_squared_error: 0.0755\n",
      "Epoch 4/5\n",
      "15569/15569 [==============================] - 66s 4ms/step - loss: 0.0920 - mean_squared_error: 0.0536 - val_loss: 0.1444 - val_mean_squared_error: 0.1187\n",
      "Epoch 5/5\n",
      "15569/15569 [==============================] - 61s 4ms/step - loss: 0.0862 - mean_squared_error: 0.0513 - val_loss: 0.0879 - val_mean_squared_error: 0.0718\n",
      "Train on 15569 samples, validate on 3893 samples\n",
      "Epoch 1/5\n",
      "15569/15569 [==============================] - 63s 4ms/step - loss: 0.0645 - mean_squared_error: 0.0462 - val_loss: 0.0945 - val_mean_squared_error: 0.0779\n",
      "Epoch 2/5\n",
      "15569/15569 [==============================] - 63s 4ms/step - loss: 0.0582 - mean_squared_error: 0.0416 - val_loss: 0.0914 - val_mean_squared_error: 0.0810\n",
      "Epoch 3/5\n",
      "15569/15569 [==============================] - 64s 4ms/step - loss: 0.0526 - mean_squared_error: 0.0412 - val_loss: 0.0753 - val_mean_squared_error: 0.0684\n",
      "Epoch 4/5\n",
      "15569/15569 [==============================] - 58s 4ms/step - loss: 0.0468 - mean_squared_error: 0.0384 - val_loss: 0.0778 - val_mean_squared_error: 0.0657\n",
      "Epoch 5/5\n",
      "15569/15569 [==============================] - 59s 4ms/step - loss: 0.0433 - mean_squared_error: 0.0350 - val_loss: 0.0713 - val_mean_squared_error: 0.0656\n",
      "Train on 15569 samples, validate on 3893 samples\n",
      "Epoch 1/5\n",
      "15569/15569 [==============================] - 63s 4ms/step - loss: 0.0425 - mean_squared_error: 0.0354 - val_loss: 0.0929 - val_mean_squared_error: 0.0859\n",
      "Epoch 2/5\n",
      "15569/15569 [==============================] - 67s 4ms/step - loss: 0.0404 - mean_squared_error: 0.0347 - val_loss: 0.0825 - val_mean_squared_error: 0.0763\n",
      "Epoch 3/5\n",
      "15569/15569 [==============================] - 66s 4ms/step - loss: 0.0398 - mean_squared_error: 0.0345 - val_loss: 0.0690 - val_mean_squared_error: 0.0642\n",
      "Epoch 4/5\n",
      "15569/15569 [==============================] - 65s 4ms/step - loss: 0.0372 - mean_squared_error: 0.0331 - val_loss: 0.0684 - val_mean_squared_error: 0.0645\n",
      "Epoch 5/5\n",
      "15569/15569 [==============================] - 66s 4ms/step - loss: 0.0372 - mean_squared_error: 0.0334 - val_loss: 0.0906 - val_mean_squared_error: 0.0864\n",
      "Train on 15569 samples, validate on 3893 samples\n",
      "Epoch 1/5\n",
      "15569/15569 [==============================] - 64s 4ms/step - loss: 0.0355 - mean_squared_error: 0.0318 - val_loss: 0.0637 - val_mean_squared_error: 0.0603\n",
      "Epoch 2/5\n",
      "15569/15569 [==============================] - 66s 4ms/step - loss: 0.0340 - mean_squared_error: 0.0311 - val_loss: 0.0666 - val_mean_squared_error: 0.0640\n",
      "Epoch 3/5\n",
      "15569/15569 [==============================] - 63s 4ms/step - loss: 0.0317 - mean_squared_error: 0.0293 - val_loss: 0.0649 - val_mean_squared_error: 0.0625\n",
      "Epoch 4/5\n",
      "15569/15569 [==============================] - 65s 4ms/step - loss: 0.0319 - mean_squared_error: 0.0291 - val_loss: 0.0655 - val_mean_squared_error: 0.0634\n",
      "Epoch 5/5\n",
      "15569/15569 [==============================] - 64s 4ms/step - loss: 0.0334 - mean_squared_error: 0.0312 - val_loss: 0.1281 - val_mean_squared_error: 0.1259\n",
      "Train on 15569 samples, validate on 3893 samples\n",
      "Epoch 1/5\n",
      "15569/15569 [==============================] - 64s 4ms/step - loss: 0.0333 - mean_squared_error: 0.0303 - val_loss: 0.0649 - val_mean_squared_error: 0.0624\n",
      "Epoch 2/5\n",
      "15569/15569 [==============================] - 69s 4ms/step - loss: 0.0293 - mean_squared_error: 0.0272 - val_loss: 0.0628 - val_mean_squared_error: 0.0610\n",
      "Epoch 3/5\n",
      "15569/15569 [==============================] - 67s 4ms/step - loss: 0.0297 - mean_squared_error: 0.0278 - val_loss: 0.0603 - val_mean_squared_error: 0.0585\n",
      "Epoch 4/5\n",
      "15569/15569 [==============================] - 68s 4ms/step - loss: 0.0296 - mean_squared_error: 0.0278 - val_loss: 0.0619 - val_mean_squared_error: 0.0601\n",
      "Epoch 5/5\n",
      "15569/15569 [==============================] - 66s 4ms/step - loss: 0.0296 - mean_squared_error: 0.0273 - val_loss: 0.0641 - val_mean_squared_error: 0.0619\n",
      "Train on 15569 samples, validate on 3893 samples\n",
      "Epoch 1/5\n",
      "15569/15569 [==============================] - 68s 4ms/step - loss: 0.0294 - mean_squared_error: 0.0274 - val_loss: 0.0768 - val_mean_squared_error: 0.0750\n",
      "Epoch 2/5\n",
      "15569/15569 [==============================] - 67s 4ms/step - loss: 0.0284 - mean_squared_error: 0.0267 - val_loss: 0.0679 - val_mean_squared_error: 0.0663\n",
      "Epoch 3/5\n",
      "15569/15569 [==============================] - 71s 5ms/step - loss: 0.0292 - mean_squared_error: 0.0274 - val_loss: 0.0638 - val_mean_squared_error: 0.0614\n",
      "Epoch 4/5\n",
      "15569/15569 [==============================] - 71s 5ms/step - loss: 0.0281 - mean_squared_error: 0.0263 - val_loss: 0.0646 - val_mean_squared_error: 0.0617\n",
      "Epoch 5/5\n",
      "15569/15569 [==============================] - 73s 5ms/step - loss: 0.0282 - mean_squared_error: 0.0263 - val_loss: 0.0744 - val_mean_squared_error: 0.0725\n",
      "Train on 15569 samples, validate on 3893 samples\n",
      "Epoch 1/5\n",
      "15569/15569 [==============================] - 71s 5ms/step - loss: 0.0286 - mean_squared_error: 0.0269 - val_loss: 0.0612 - val_mean_squared_error: 0.0596\n",
      "Epoch 2/5\n",
      "15569/15569 [==============================] - 63s 4ms/step - loss: 0.0265 - mean_squared_error: 0.0250 - val_loss: 0.0633 - val_mean_squared_error: 0.0619\n",
      "Epoch 3/5\n",
      "15569/15569 [==============================] - 60s 4ms/step - loss: 0.0273 - mean_squared_error: 0.0259 - val_loss: 0.0630 - val_mean_squared_error: 0.0617\n",
      "Epoch 4/5\n",
      "15569/15569 [==============================] - 69s 4ms/step - loss: 0.0258 - mean_squared_error: 0.0245 - val_loss: 0.0605 - val_mean_squared_error: 0.0593\n",
      "Epoch 5/5\n",
      "15569/15569 [==============================] - 71s 5ms/step - loss: 0.0252 - mean_squared_error: 0.0240 - val_loss: 0.0666 - val_mean_squared_error: 0.0653\n",
      "4869/4869 [==============================] - 4s 900us/step\n",
      "model10_combine Loss = 0.0509547233221\n",
      "model10_combine Test Accuracy = 0.0496848577155\n",
      "[0.050954723322117909, 0.049684857715492768]\n",
      "Train on 15571 samples, validate on 3893 samples\n",
      "Epoch 1/5\n",
      "15571/15571 [==============================] - 76s 5ms/step - loss: 26.8947 - mean_squared_error: 3.7543 - val_loss: 19.2477 - val_mean_squared_error: 0.6642\n",
      "Epoch 2/5\n",
      "15571/15571 [==============================] - 70s 4ms/step - loss: 14.6719 - mean_squared_error: 0.7395 - val_loss: 10.8064 - val_mean_squared_error: 1.1122\n",
      "Epoch 3/5\n",
      "15571/15571 [==============================] - 65s 4ms/step - loss: 7.0169 - mean_squared_error: 0.4136 - val_loss: 4.6099 - val_mean_squared_error: 0.5398\n",
      "Epoch 4/5\n",
      "15571/15571 [==============================] - 65s 4ms/step - loss: 2.8222 - mean_squared_error: 0.2940 - val_loss: 2.0563 - val_mean_squared_error: 0.6883\n",
      "Epoch 5/5\n",
      "15571/15571 [==============================] - 64s 4ms/step - loss: 1.0015 - mean_squared_error: 0.2183 - val_loss: 0.5855 - val_mean_squared_error: 0.1961\n",
      "Train on 15571 samples, validate on 3893 samples\n",
      "Epoch 1/5\n",
      "15571/15571 [==============================] - 67s 4ms/step - loss: 0.5164 - mean_squared_error: 0.2462 - val_loss: 1.2169 - val_mean_squared_error: 0.9747\n",
      "Epoch 2/5\n",
      "15571/15571 [==============================] - 66s 4ms/step - loss: 0.3917 - mean_squared_error: 0.2164 - val_loss: 0.9034 - val_mean_squared_error: 0.7580\n",
      "Epoch 3/5\n",
      "15571/15571 [==============================] - 62s 4ms/step - loss: 0.5184 - mean_squared_error: 0.3025 - val_loss: 1.0602 - val_mean_squared_error: 0.6544\n",
      "Epoch 4/5\n",
      "15571/15571 [==============================] - 68s 4ms/step - loss: 0.4989 - mean_squared_error: 0.2415 - val_loss: 0.5893 - val_mean_squared_error: 0.4145\n",
      "Epoch 5/5\n",
      "15571/15571 [==============================] - 69s 4ms/step - loss: 0.3959 - mean_squared_error: 0.1804 - val_loss: 0.3757 - val_mean_squared_error: 0.1915\n",
      "Train on 15571 samples, validate on 3893 samples\n",
      "Epoch 1/5\n",
      "15571/15571 [==============================] - 69s 4ms/step - loss: 0.3035 - mean_squared_error: 0.1438 - val_loss: 0.4105 - val_mean_squared_error: 0.3337\n",
      "Epoch 2/5\n",
      "15571/15571 [==============================] - 65s 4ms/step - loss: 0.2241 - mean_squared_error: 0.1075 - val_loss: 0.2624 - val_mean_squared_error: 0.1768\n",
      "Epoch 3/5\n",
      "15571/15571 [==============================] - 65s 4ms/step - loss: 0.1641 - mean_squared_error: 0.0823 - val_loss: 0.1728 - val_mean_squared_error: 0.1068\n",
      "Epoch 4/5\n",
      "15571/15571 [==============================] - 68s 4ms/step - loss: 0.1124 - mean_squared_error: 0.0646 - val_loss: 0.1303 - val_mean_squared_error: 0.0796\n",
      "Epoch 5/5\n",
      "15571/15571 [==============================] - 70s 4ms/step - loss: 0.1057 - mean_squared_error: 0.0613 - val_loss: 0.1542 - val_mean_squared_error: 0.1097\n",
      "Train on 15571 samples, validate on 3893 samples\n",
      "Epoch 1/5\n",
      "15571/15571 [==============================] - 70s 5ms/step - loss: 0.1007 - mean_squared_error: 0.0552 - val_loss: 0.1428 - val_mean_squared_error: 0.1134\n",
      "Epoch 2/5\n",
      "15571/15571 [==============================] - 71s 5ms/step - loss: 0.0770 - mean_squared_error: 0.0489 - val_loss: 0.1258 - val_mean_squared_error: 0.0791\n",
      "Epoch 3/5\n",
      "15571/15571 [==============================] - 69s 4ms/step - loss: 0.0639 - mean_squared_error: 0.0444 - val_loss: 0.1132 - val_mean_squared_error: 0.0964\n",
      "Epoch 4/5\n",
      "15571/15571 [==============================] - 63s 4ms/step - loss: 0.0659 - mean_squared_error: 0.0442 - val_loss: 0.0759 - val_mean_squared_error: 0.0617\n",
      "Epoch 5/5\n",
      "15571/15571 [==============================] - 66s 4ms/step - loss: 0.0632 - mean_squared_error: 0.0434 - val_loss: 0.0843 - val_mean_squared_error: 0.0645\n",
      "Train on 15571 samples, validate on 3893 samples\n",
      "Epoch 1/5\n",
      "15571/15571 [==============================] - 71s 5ms/step - loss: 0.0589 - mean_squared_error: 0.0425 - val_loss: 0.0688 - val_mean_squared_error: 0.0586\n",
      "Epoch 2/5\n",
      "15571/15571 [==============================] - 72s 5ms/step - loss: 0.0563 - mean_squared_error: 0.0395 - val_loss: 0.0724 - val_mean_squared_error: 0.0597\n",
      "Epoch 3/5\n",
      "15571/15571 [==============================] - 68s 4ms/step - loss: 0.0485 - mean_squared_error: 0.0378 - val_loss: 0.0757 - val_mean_squared_error: 0.0689\n",
      "Epoch 4/5\n",
      "15571/15571 [==============================] - 67s 4ms/step - loss: 0.0462 - mean_squared_error: 0.0362 - val_loss: 0.0636 - val_mean_squared_error: 0.0556\n",
      "Epoch 5/5\n",
      "15571/15571 [==============================] - 70s 5ms/step - loss: 0.0455 - mean_squared_error: 0.0361 - val_loss: 0.0651 - val_mean_squared_error: 0.0601\n",
      "Train on 15571 samples, validate on 3893 samples\n",
      "Epoch 1/5\n",
      "15571/15571 [==============================] - 72s 5ms/step - loss: 0.0414 - mean_squared_error: 0.0346 - val_loss: 0.0731 - val_mean_squared_error: 0.0668\n",
      "Epoch 2/5\n",
      "15571/15571 [==============================] - 71s 5ms/step - loss: 0.0448 - mean_squared_error: 0.0346 - val_loss: 0.0879 - val_mean_squared_error: 0.0589\n",
      "Epoch 3/5\n",
      "15571/15571 [==============================] - 69s 4ms/step - loss: 0.0432 - mean_squared_error: 0.0343 - val_loss: 0.0698 - val_mean_squared_error: 0.0614\n",
      "Epoch 4/5\n",
      "15571/15571 [==============================] - 70s 5ms/step - loss: 0.0372 - mean_squared_error: 0.0320 - val_loss: 0.0637 - val_mean_squared_error: 0.0591\n",
      "Epoch 5/5\n",
      "15571/15571 [==============================] - 71s 5ms/step - loss: 0.0369 - mean_squared_error: 0.0318 - val_loss: 0.0700 - val_mean_squared_error: 0.0665\n",
      "Train on 15571 samples, validate on 3893 samples\n",
      "Epoch 1/5\n",
      "15571/15571 [==============================] - 65s 4ms/step - loss: 0.0349 - mean_squared_error: 0.0314 - val_loss: 0.0610 - val_mean_squared_error: 0.0566\n",
      "Epoch 2/5\n",
      "15571/15571 [==============================] - 65s 4ms/step - loss: 0.0352 - mean_squared_error: 0.0315 - val_loss: 0.0575 - val_mean_squared_error: 0.0540\n",
      "Epoch 3/5\n",
      "15571/15571 [==============================] - 69s 4ms/step - loss: 0.0358 - mean_squared_error: 0.0312 - val_loss: 0.0562 - val_mean_squared_error: 0.0522\n",
      "Epoch 4/5\n",
      "15571/15571 [==============================] - 71s 5ms/step - loss: 0.0361 - mean_squared_error: 0.0312 - val_loss: 0.0713 - val_mean_squared_error: 0.0618\n",
      "Epoch 5/5\n",
      "15571/15571 [==============================] - 70s 5ms/step - loss: 0.0355 - mean_squared_error: 0.0307 - val_loss: 0.0609 - val_mean_squared_error: 0.0571\n",
      "Train on 15571 samples, validate on 3893 samples\n",
      "Epoch 1/5\n",
      "15571/15571 [==============================] - 64s 4ms/step - loss: 0.0322 - mean_squared_error: 0.0294 - val_loss: 0.0546 - val_mean_squared_error: 0.0532\n",
      "Epoch 2/5\n",
      "15571/15571 [==============================] - 63s 4ms/step - loss: 0.0294 - mean_squared_error: 0.0281 - val_loss: 0.0574 - val_mean_squared_error: 0.0563\n",
      "Epoch 3/5\n",
      "15571/15571 [==============================] - 69s 4ms/step - loss: 0.0309 - mean_squared_error: 0.0296 - val_loss: 0.0594 - val_mean_squared_error: 0.0581\n",
      "Epoch 4/5\n",
      "15571/15571 [==============================] - 70s 4ms/step - loss: 0.0299 - mean_squared_error: 0.0287 - val_loss: 0.0595 - val_mean_squared_error: 0.0582\n",
      "Epoch 5/5\n",
      "15571/15571 [==============================] - 69s 4ms/step - loss: 0.0288 - mean_squared_error: 0.0276 - val_loss: 0.0554 - val_mean_squared_error: 0.0542\n",
      "Train on 15571 samples, validate on 3893 samples\n",
      "Epoch 1/5\n",
      "15571/15571 [==============================] - 70s 4ms/step - loss: 0.0282 - mean_squared_error: 0.0270 - val_loss: 0.0528 - val_mean_squared_error: 0.0517\n",
      "Epoch 2/5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15571/15571 [==============================] - 70s 5ms/step - loss: 0.0284 - mean_squared_error: 0.0273 - val_loss: 0.0734 - val_mean_squared_error: 0.0723\n",
      "Epoch 3/5\n",
      "15571/15571 [==============================] - 67s 4ms/step - loss: 0.0283 - mean_squared_error: 0.0271 - val_loss: 0.0536 - val_mean_squared_error: 0.0524\n",
      "Epoch 4/5\n",
      "15571/15571 [==============================] - 62s 4ms/step - loss: 0.0281 - mean_squared_error: 0.0270 - val_loss: 0.0576 - val_mean_squared_error: 0.0564\n",
      "Epoch 5/5\n",
      "15571/15571 [==============================] - 64s 4ms/step - loss: 0.0280 - mean_squared_error: 0.0269 - val_loss: 0.0548 - val_mean_squared_error: 0.0536\n",
      "Train on 15571 samples, validate on 3893 samples\n",
      "Epoch 1/5\n",
      "15571/15571 [==============================] - 70s 5ms/step - loss: 0.0274 - mean_squared_error: 0.0263 - val_loss: 0.0536 - val_mean_squared_error: 0.0523\n",
      "Epoch 2/5\n",
      "15571/15571 [==============================] - 67s 4ms/step - loss: 0.0280 - mean_squared_error: 0.0268 - val_loss: 0.0537 - val_mean_squared_error: 0.0526\n",
      "Epoch 3/5\n",
      "15571/15571 [==============================] - 69s 4ms/step - loss: 0.0277 - mean_squared_error: 0.0266 - val_loss: 0.0551 - val_mean_squared_error: 0.0540\n",
      "Epoch 4/5\n",
      "15571/15571 [==============================] - 72s 5ms/step - loss: 0.0267 - mean_squared_error: 0.0256 - val_loss: 0.0566 - val_mean_squared_error: 0.0554\n",
      "Epoch 5/5\n",
      "15571/15571 [==============================] - 72s 5ms/step - loss: 0.0284 - mean_squared_error: 0.0272 - val_loss: 0.0551 - val_mean_squared_error: 0.0540\n",
      "4867/4867 [==============================] - 5s 964us/step\n",
      "model10_combine Loss = 0.0362805197842\n",
      "model10_combine Test Accuracy = 0.0351574748543\n",
      "[0.036280519784243903, 0.035157474854324591]\n",
      "Train on 15571 samples, validate on 3893 samples\n",
      "Epoch 1/5\n",
      "15571/15571 [==============================] - 79s 5ms/step - loss: 26.0850 - mean_squared_error: 3.2112 - val_loss: 18.6700 - val_mean_squared_error: 0.7040\n",
      "Epoch 2/5\n",
      "15571/15571 [==============================] - 71s 5ms/step - loss: 13.7080 - mean_squared_error: 0.6531 - val_loss: 10.9100 - val_mean_squared_error: 2.2323\n",
      "Epoch 3/5\n",
      "15571/15571 [==============================] - 68s 4ms/step - loss: 6.0708 - mean_squared_error: 0.4186 - val_loss: 3.7496 - val_mean_squared_error: 0.4904\n",
      "Epoch 4/5\n",
      "15571/15571 [==============================] - 68s 4ms/step - loss: 2.2353 - mean_squared_error: 0.3025 - val_loss: 1.2607 - val_mean_squared_error: 0.2871\n",
      "Epoch 5/5\n",
      "15571/15571 [==============================] - 69s 4ms/step - loss: 0.7801 - mean_squared_error: 0.2231 - val_loss: 0.4863 - val_mean_squared_error: 0.1947\n",
      "Train on 15571 samples, validate on 3893 samples\n",
      "Epoch 1/5\n",
      "15571/15571 [==============================] - 63s 4ms/step - loss: 0.4703 - mean_squared_error: 0.2427 - val_loss: 0.6020 - val_mean_squared_error: 0.4413\n",
      "Epoch 2/5\n",
      "15571/15571 [==============================] - 69s 4ms/step - loss: 0.5445 - mean_squared_error: 0.3375 - val_loss: 1.7119 - val_mean_squared_error: 1.3079\n",
      "Epoch 3/5\n",
      "15571/15571 [==============================] - 65s 4ms/step - loss: 0.6059 - mean_squared_error: 0.3530 - val_loss: 0.8147 - val_mean_squared_error: 0.5377\n",
      "Epoch 4/5\n",
      "15571/15571 [==============================] - 71s 5ms/step - loss: 0.6685 - mean_squared_error: 0.3632 - val_loss: 0.4209 - val_mean_squared_error: 0.2254\n",
      "Epoch 5/5\n",
      "15571/15571 [==============================] - 70s 5ms/step - loss: 0.3813 - mean_squared_error: 0.1930 - val_loss: 1.0953 - val_mean_squared_error: 0.6409\n",
      "Train on 15571 samples, validate on 3893 samples\n",
      "Epoch 1/5\n",
      "15571/15571 [==============================] - 70s 4ms/step - loss: 0.3043 - mean_squared_error: 0.1331 - val_loss: 0.3710 - val_mean_squared_error: 0.2651\n",
      "Epoch 2/5\n",
      "15571/15571 [==============================] - 71s 5ms/step - loss: 0.2354 - mean_squared_error: 0.1105 - val_loss: 0.2852 - val_mean_squared_error: 0.2090\n",
      "Epoch 3/5\n",
      "15571/15571 [==============================] - 73s 5ms/step - loss: 0.1654 - mean_squared_error: 0.0865 - val_loss: 0.1585 - val_mean_squared_error: 0.1138\n",
      "Epoch 4/5\n",
      "15571/15571 [==============================] - 71s 5ms/step - loss: 0.1199 - mean_squared_error: 0.0682 - val_loss: 0.1704 - val_mean_squared_error: 0.1125\n",
      "Epoch 5/5\n",
      "15571/15571 [==============================] - 72s 5ms/step - loss: 0.1133 - mean_squared_error: 0.0667 - val_loss: 0.1399 - val_mean_squared_error: 0.1076\n",
      "Train on 15571 samples, validate on 3893 samples\n",
      "Epoch 1/5\n",
      "15571/15571 [==============================] - 73s 5ms/step - loss: 0.1056 - mean_squared_error: 0.0612 - val_loss: 0.1253 - val_mean_squared_error: 0.0870\n",
      "Epoch 2/5\n",
      "15571/15571 [==============================] - 74s 5ms/step - loss: 0.0850 - mean_squared_error: 0.0539 - val_loss: 0.1550 - val_mean_squared_error: 0.1328\n",
      "Epoch 3/5\n",
      "15571/15571 [==============================] - 66s 4ms/step - loss: 0.0784 - mean_squared_error: 0.0520 - val_loss: 0.1100 - val_mean_squared_error: 0.0826\n",
      "Epoch 4/5\n",
      "15571/15571 [==============================] - 58s 4ms/step - loss: 0.0704 - mean_squared_error: 0.0472 - val_loss: 0.0897 - val_mean_squared_error: 0.0683\n",
      "Epoch 5/5\n",
      "15571/15571 [==============================] - 59s 4ms/step - loss: 0.0614 - mean_squared_error: 0.0431 - val_loss: 0.0738 - val_mean_squared_error: 0.0628\n",
      "Train on 15571 samples, validate on 3893 samples\n",
      "Epoch 1/5\n",
      "15571/15571 [==============================] - 63s 4ms/step - loss: 0.0530 - mean_squared_error: 0.0398 - val_loss: 0.0953 - val_mean_squared_error: 0.0821\n",
      "Epoch 2/5\n",
      "15571/15571 [==============================] - 65s 4ms/step - loss: 0.0516 - mean_squared_error: 0.0385 - val_loss: 0.0839 - val_mean_squared_error: 0.0657\n",
      "Epoch 3/5\n",
      "15571/15571 [==============================] - 65s 4ms/step - loss: 0.0506 - mean_squared_error: 0.0376 - val_loss: 0.0835 - val_mean_squared_error: 0.0747\n",
      "Epoch 4/5\n",
      "15571/15571 [==============================] - 65s 4ms/step - loss: 0.0432 - mean_squared_error: 0.0358 - val_loss: 0.0671 - val_mean_squared_error: 0.0607\n",
      "Epoch 5/5\n",
      "15571/15571 [==============================] - 61s 4ms/step - loss: 0.0384 - mean_squared_error: 0.0340 - val_loss: 0.0637 - val_mean_squared_error: 0.0600\n",
      "Train on 15571 samples, validate on 3893 samples\n",
      "Epoch 1/5\n",
      "15571/15571 [==============================] - 62s 4ms/step - loss: 0.0363 - mean_squared_error: 0.0322 - val_loss: 0.0610 - val_mean_squared_error: 0.0581\n",
      "Epoch 2/5\n",
      "15571/15571 [==============================] - 64s 4ms/step - loss: 0.0363 - mean_squared_error: 0.0326 - val_loss: 0.0671 - val_mean_squared_error: 0.0632\n",
      "Epoch 3/5\n",
      "15571/15571 [==============================] - 66s 4ms/step - loss: 0.0339 - mean_squared_error: 0.0308 - val_loss: 0.0724 - val_mean_squared_error: 0.0693\n",
      "Epoch 4/5\n",
      "15571/15571 [==============================] - 67s 4ms/step - loss: 0.0333 - mean_squared_error: 0.0304 - val_loss: 0.0931 - val_mean_squared_error: 0.0907\n",
      "Epoch 5/5\n",
      "15571/15571 [==============================] - 60s 4ms/step - loss: 0.0328 - mean_squared_error: 0.0299 - val_loss: 0.0646 - val_mean_squared_error: 0.0616\n",
      "Train on 15571 samples, validate on 3893 samples\n",
      "Epoch 1/5\n",
      "15571/15571 [==============================] - 66s 4ms/step - loss: 0.0318 - mean_squared_error: 0.0293 - val_loss: 0.0665 - val_mean_squared_error: 0.0641\n",
      "Epoch 2/5\n",
      "15571/15571 [==============================] - 66s 4ms/step - loss: 0.0297 - mean_squared_error: 0.0275 - val_loss: 0.0615 - val_mean_squared_error: 0.0596\n",
      "Epoch 3/5\n",
      "15571/15571 [==============================] - 65s 4ms/step - loss: 0.0303 - mean_squared_error: 0.0282 - val_loss: 0.0624 - val_mean_squared_error: 0.0605\n",
      "Epoch 4/5\n",
      "15571/15571 [==============================] - 66s 4ms/step - loss: 0.0285 - mean_squared_error: 0.0268 - val_loss: 0.0637 - val_mean_squared_error: 0.0618\n",
      "Epoch 5/5\n",
      "15571/15571 [==============================] - 65s 4ms/step - loss: 0.0298 - mean_squared_error: 0.0279 - val_loss: 0.0808 - val_mean_squared_error: 0.0789\n",
      "Train on 15571 samples, validate on 3893 samples\n",
      "Epoch 1/5\n",
      "15571/15571 [==============================] - 59s 4ms/step - loss: 0.0302 - mean_squared_error: 0.0284 - val_loss: 0.0619 - val_mean_squared_error: 0.0603\n",
      "Epoch 2/5\n",
      "15571/15571 [==============================] - 64s 4ms/step - loss: 0.0292 - mean_squared_error: 0.0276 - val_loss: 0.0611 - val_mean_squared_error: 0.0595\n",
      "Epoch 3/5\n",
      "15571/15571 [==============================] - 64s 4ms/step - loss: 0.0279 - mean_squared_error: 0.0264 - val_loss: 0.0641 - val_mean_squared_error: 0.0625\n",
      "Epoch 4/5\n",
      "15571/15571 [==============================] - 64s 4ms/step - loss: 0.0287 - mean_squared_error: 0.0272 - val_loss: 0.0616 - val_mean_squared_error: 0.0603\n",
      "Epoch 5/5\n",
      "15571/15571 [==============================] - 62s 4ms/step - loss: 0.0274 - mean_squared_error: 0.0259 - val_loss: 0.0661 - val_mean_squared_error: 0.0646\n",
      "Train on 15571 samples, validate on 3893 samples\n",
      "Epoch 1/5\n",
      "15571/15571 [==============================] - 58s 4ms/step - loss: 0.0270 - mean_squared_error: 0.0255 - val_loss: 0.0625 - val_mean_squared_error: 0.0610\n",
      "Epoch 2/5\n",
      "15571/15571 [==============================] - 63s 4ms/step - loss: 0.0266 - mean_squared_error: 0.0251 - val_loss: 0.0600 - val_mean_squared_error: 0.0585\n",
      "Epoch 3/5\n",
      "15571/15571 [==============================] - 65s 4ms/step - loss: 0.0265 - mean_squared_error: 0.0251 - val_loss: 0.0641 - val_mean_squared_error: 0.0627\n",
      "Epoch 4/5\n",
      "15571/15571 [==============================] - 65s 4ms/step - loss: 0.0270 - mean_squared_error: 0.0255 - val_loss: 0.0643 - val_mean_squared_error: 0.0628\n",
      "Epoch 5/5\n",
      "15571/15571 [==============================] - 67s 4ms/step - loss: 0.0262 - mean_squared_error: 0.0248 - val_loss: 0.0779 - val_mean_squared_error: 0.0764\n",
      "Train on 15571 samples, validate on 3893 samples\n",
      "Epoch 1/5\n",
      "15571/15571 [==============================] - 64s 4ms/step - loss: 0.0261 - mean_squared_error: 0.0247 - val_loss: 0.0639 - val_mean_squared_error: 0.0626\n",
      "Epoch 2/5\n",
      "15571/15571 [==============================] - 64s 4ms/step - loss: 0.0263 - mean_squared_error: 0.0248 - val_loss: 0.0599 - val_mean_squared_error: 0.0584\n",
      "Epoch 3/5\n",
      "15571/15571 [==============================] - 65s 4ms/step - loss: 0.0256 - mean_squared_error: 0.0242 - val_loss: 0.0600 - val_mean_squared_error: 0.0585\n",
      "Epoch 4/5\n",
      "15571/15571 [==============================] - 65s 4ms/step - loss: 0.0251 - mean_squared_error: 0.0237 - val_loss: 0.0633 - val_mean_squared_error: 0.0620\n",
      "Epoch 5/5\n",
      "15571/15571 [==============================] - 67s 4ms/step - loss: 0.0249 - mean_squared_error: 0.0235 - val_loss: 0.0632 - val_mean_squared_error: 0.0618\n",
      "4867/4867 [==============================] - 4s 796us/step\n",
      "model10_combine Loss = 0.0509481510744\n",
      "model10_combine Test Accuracy = 0.0495485533966\n",
      "[0.05094815107440958, 0.049548553396647828]\n",
      "Train on 15572 samples, validate on 3893 samples\n",
      "Epoch 1/5\n",
      "  144/15572 [..............................] - ETA: 11:14 - loss: 67.2578 - mean_squared_error: 41.0465"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-c724d6e1d36a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mmodel10_combine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'adam'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'mse'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'mse'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m         \u001b[0mlines10_combine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel10_combine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstores\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mroads\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpois\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m16\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_split\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m   1703\u001b[0m                               \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1704\u001b[0m                               \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1705\u001b[0;31m                               validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m   1706\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1707\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m_fit_loop\u001b[0;34m(self, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[1;32m   1233\u001b[0m                         \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1234\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1235\u001b[0;31m                     \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1236\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1237\u001b[0m                         \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2476\u001b[0m         \u001b[0msession\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2477\u001b[0m         updated = session.run(fetches=fetches, feed_dict=feed_dict,\n\u001b[0;32m-> 2478\u001b[0;31m                               **self.session_kwargs)\n\u001b[0m\u001b[1;32m   2479\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mupdated\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2480\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    887\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 889\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    890\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    891\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1118\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1119\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1120\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1121\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1122\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1315\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1316\u001b[0m       return self._do_call(_run_fn, self._session, feeds, fetches, targets,\n\u001b[0;32m-> 1317\u001b[0;31m                            options, run_metadata)\n\u001b[0m\u001b[1;32m   1318\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1319\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1321\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1322\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1323\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1324\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1325\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1300\u001b[0m           return tf_session.TF_Run(session, options,\n\u001b[1;32m   1301\u001b[0m                                    \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1302\u001b[0;31m                                    status, run_metadata)\n\u001b[0m\u001b[1;32m   1303\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1304\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for train, test in kfold.split(stores, origin_y):\n",
    "    model10_stores, instore = ResNet50(input_shape=stores.shape[1:])\n",
    "    model10_roads, inroad = ResNet50(input_shape=roads.shape[1:])\n",
    "    model10_pois, in3poi = ResNet50(input_shape=pois.shape[1:])\n",
    "    \n",
    "    model10_combine = Three_ResNet(model10_stores, model10_roads, model10_pois, [instore, inroad, in3poi])\n",
    "    model10_combine.compile(optimizer='adam', loss='mse', metrics=['mse'])\n",
    "    for _ in range(10):\n",
    "        lines10_combine = model10_combine.fit([stores[train], roads[train], pois[train]], y_data[train], epochs = 5, batch_size = 16, validation_split=0.2)\n",
    "        \n",
    "        \n",
    "    preds10_combine = model10_combine.evaluate([stores[test], roads[test], pois[test]], y_data[test])\n",
    "    print (\"model10_combine Loss = \" + str(preds10_combine[0]))\n",
    "    print (\"model10_combine Test Accuracy = \" + str(preds10_combine[1]))\n",
    "    print(preds10_combine)\n",
    "    cvscores.append(preds10_combine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[0.050954723322117909, 0.049684857715492768],\n",
       " [0.036280519784243903, 0.035157474854324591],\n",
       " [0.05094815107440958, 0.049548553396647828]]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cvscores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 15572 samples, validate on 3893 samples\n",
      "Epoch 1/5\n",
      "15572/15572 [==============================] - 71s 5ms/step - loss: 26.2505 - mean_squared_error: 3.4225 - val_loss: 23.3164 - val_mean_squared_error: 5.3536\n",
      "Epoch 2/5\n",
      "15572/15572 [==============================] - 67s 4ms/step - loss: 13.7498 - mean_squared_error: 0.5850 - val_loss: 10.0140 - val_mean_squared_error: 1.1401\n",
      "Epoch 3/5\n",
      "15572/15572 [==============================] - 68s 4ms/step - loss: 6.2783 - mean_squared_error: 0.3857 - val_loss: 3.8856 - val_mean_squared_error: 0.3751\n",
      "Epoch 4/5\n",
      "15572/15572 [==============================] - 65s 4ms/step - loss: 2.4181 - mean_squared_error: 0.2851 - val_loss: 1.3920 - val_mean_squared_error: 0.2742\n",
      "Epoch 5/5\n",
      "15572/15572 [==============================] - 66s 4ms/step - loss: 0.8450 - mean_squared_error: 0.2023 - val_loss: 0.6004 - val_mean_squared_error: 0.2627\n",
      "4866/4866 [==============================] - 4s 826us/step\n",
      "model10_combine Loss = 0.579778457736\n",
      "model10_combine Test Accuracy = 0.242134913196\n",
      "Train on 15572 samples, validate on 3893 samples\n",
      "Epoch 1/5\n",
      "15572/15572 [==============================] - 62s 4ms/step - loss: 0.5318 - mean_squared_error: 0.2653 - val_loss: 0.5423 - val_mean_squared_error: 0.3294\n",
      "Epoch 2/5\n",
      "15572/15572 [==============================] - 68s 4ms/step - loss: 0.4657 - mean_squared_error: 0.2726 - val_loss: 0.6549 - val_mean_squared_error: 0.4371\n",
      "Epoch 3/5\n",
      "15572/15572 [==============================] - 70s 4ms/step - loss: 0.5307 - mean_squared_error: 0.2992 - val_loss: 0.6949 - val_mean_squared_error: 0.5323\n",
      "Epoch 4/5\n",
      "15572/15572 [==============================] - 71s 5ms/step - loss: 0.4788 - mean_squared_error: 0.2392 - val_loss: 1.1897 - val_mean_squared_error: 0.6653\n",
      "Epoch 5/5\n",
      "15572/15572 [==============================] - 71s 5ms/step - loss: 0.5681 - mean_squared_error: 0.2039 - val_loss: 0.5078 - val_mean_squared_error: 0.3006\n",
      "4866/4866 [==============================] - 4s 912us/step\n",
      "model10_combine Loss = 0.465384477005\n",
      "model10_combine Test Accuracy = 0.258251623134\n",
      "Train on 15572 samples, validate on 3893 samples\n",
      "Epoch 1/5\n",
      "15572/15572 [==============================] - 67s 4ms/step - loss: 0.5368 - mean_squared_error: 0.1763 - val_loss: 0.3034 - val_mean_squared_error: 0.1348\n",
      "Epoch 2/5\n",
      "15572/15572 [==============================] - 67s 4ms/step - loss: 0.2494 - mean_squared_error: 0.1085 - val_loss: 0.3190 - val_mean_squared_error: 0.2201\n",
      "Epoch 3/5\n",
      "15572/15572 [==============================] - 67s 4ms/step - loss: 0.1692 - mean_squared_error: 0.0852 - val_loss: 0.2047 - val_mean_squared_error: 0.1160\n",
      "Epoch 4/5\n",
      "15572/15572 [==============================] - 68s 4ms/step - loss: 0.1269 - mean_squared_error: 0.0691 - val_loss: 0.2113 - val_mean_squared_error: 0.1514\n",
      "Epoch 5/5\n",
      "15572/15572 [==============================] - 66s 4ms/step - loss: 0.1065 - mean_squared_error: 0.0609 - val_loss: 0.1605 - val_mean_squared_error: 0.1114\n",
      "4866/4866 [==============================] - 4s 815us/step\n",
      "model10_combine Loss = 0.124194554651\n",
      "model10_combine Test Accuracy = 0.0750718287193\n",
      "Train on 15572 samples, validate on 3893 samples\n",
      "Epoch 1/5\n",
      "15572/15572 [==============================] - 68s 4ms/step - loss: 0.0850 - mean_squared_error: 0.0511 - val_loss: 0.1006 - val_mean_squared_error: 0.0795\n",
      "Epoch 2/5\n",
      "15572/15572 [==============================] - 61s 4ms/step - loss: 0.0805 - mean_squared_error: 0.0505 - val_loss: 0.1335 - val_mean_squared_error: 0.0954\n",
      "Epoch 3/5\n",
      "15572/15572 [==============================] - 65s 4ms/step - loss: 0.0677 - mean_squared_error: 0.0446 - val_loss: 0.0992 - val_mean_squared_error: 0.0824\n",
      "Epoch 4/5\n",
      "15572/15572 [==============================] - 66s 4ms/step - loss: 0.0574 - mean_squared_error: 0.0411 - val_loss: 0.0908 - val_mean_squared_error: 0.0784\n",
      "Epoch 5/5\n",
      "15572/15572 [==============================] - 64s 4ms/step - loss: 0.0572 - mean_squared_error: 0.0413 - val_loss: 0.1150 - val_mean_squared_error: 0.0933\n",
      "4866/4866 [==============================] - 4s 807us/step\n",
      "model10_combine Loss = 0.0900299588453\n",
      "model10_combine Test Accuracy = 0.0682895079169\n",
      "Train on 15572 samples, validate on 3893 samples\n",
      "Epoch 1/5\n",
      "15572/15572 [==============================] - 65s 4ms/step - loss: 0.0539 - mean_squared_error: 0.0408 - val_loss: 0.0827 - val_mean_squared_error: 0.0740\n",
      "Epoch 2/5\n",
      "15572/15572 [==============================] - 66s 4ms/step - loss: 0.0435 - mean_squared_error: 0.0347 - val_loss: 0.0867 - val_mean_squared_error: 0.0780\n",
      "Epoch 3/5\n",
      "15572/15572 [==============================] - 66s 4ms/step - loss: 0.0417 - mean_squared_error: 0.0344 - val_loss: 0.0835 - val_mean_squared_error: 0.0771\n",
      "Epoch 4/5\n",
      "15572/15572 [==============================] - 69s 4ms/step - loss: 0.0398 - mean_squared_error: 0.0338 - val_loss: 0.0793 - val_mean_squared_error: 0.0739\n",
      "Epoch 5/5\n",
      "15572/15572 [==============================] - 65s 4ms/step - loss: 0.0384 - mean_squared_error: 0.0335 - val_loss: 0.0766 - val_mean_squared_error: 0.0721\n",
      "4866/4866 [==============================] - 3s 568us/step\n",
      "model10_combine Loss = 0.0512080022455\n",
      "model10_combine Test Accuracy = 0.0467305847754\n",
      "Train on 15572 samples, validate on 3893 samples\n",
      "Epoch 1/5\n",
      "15572/15572 [==============================] - 67s 4ms/step - loss: 0.0361 - mean_squared_error: 0.0315 - val_loss: 0.1035 - val_mean_squared_error: 0.0991\n",
      "Epoch 2/5\n",
      "15572/15572 [==============================] - 69s 4ms/step - loss: 0.0363 - mean_squared_error: 0.0319 - val_loss: 0.0744 - val_mean_squared_error: 0.0704\n",
      "Epoch 3/5\n",
      "15572/15572 [==============================] - 68s 4ms/step - loss: 0.0352 - mean_squared_error: 0.0315 - val_loss: 0.0684 - val_mean_squared_error: 0.0647\n",
      "Epoch 4/5\n",
      "15572/15572 [==============================] - 60s 4ms/step - loss: 0.0336 - mean_squared_error: 0.0301 - val_loss: 0.0793 - val_mean_squared_error: 0.0749\n",
      "Epoch 5/5\n",
      "15572/15572 [==============================] - 65s 4ms/step - loss: 0.0337 - mean_squared_error: 0.0302 - val_loss: 0.0723 - val_mean_squared_error: 0.0695\n",
      "4866/4866 [==============================] - 2s 511us/step\n",
      "model10_combine Loss = 0.0408114778261\n",
      "model10_combine Test Accuracy = 0.0380246941409\n",
      "Train on 15572 samples, validate on 3893 samples\n",
      "Epoch 1/5\n",
      "15572/15572 [==============================] - 63s 4ms/step - loss: 0.0321 - mean_squared_error: 0.0292 - val_loss: 0.0743 - val_mean_squared_error: 0.0716\n",
      "Epoch 2/5\n",
      "15572/15572 [==============================] - 60s 4ms/step - loss: 0.0305 - mean_squared_error: 0.0276 - val_loss: 0.0730 - val_mean_squared_error: 0.0694\n",
      "Epoch 3/5\n",
      "15572/15572 [==============================] - 67s 4ms/step - loss: 0.0327 - mean_squared_error: 0.0294 - val_loss: 0.0677 - val_mean_squared_error: 0.0649\n",
      "Epoch 4/5\n",
      "15572/15572 [==============================] - 65s 4ms/step - loss: 0.0314 - mean_squared_error: 0.0284 - val_loss: 0.0776 - val_mean_squared_error: 0.0743\n",
      "Epoch 5/5\n",
      "15572/15572 [==============================] - 68s 4ms/step - loss: 0.0312 - mean_squared_error: 0.0281 - val_loss: 0.0690 - val_mean_squared_error: 0.0659\n",
      "4866/4866 [==============================] - 4s 874us/step\n",
      "model10_combine Loss = 0.0417416478077\n",
      "model10_combine Test Accuracy = 0.0386008433033\n",
      "Train on 15572 samples, validate on 3893 samples\n",
      "Epoch 1/5\n",
      "15572/15572 [==============================] - 69s 4ms/step - loss: 0.0302 - mean_squared_error: 0.0273 - val_loss: 0.0684 - val_mean_squared_error: 0.0659\n",
      "Epoch 2/5\n",
      "15572/15572 [==============================] - 70s 4ms/step - loss: 0.0292 - mean_squared_error: 0.0266 - val_loss: 0.0685 - val_mean_squared_error: 0.0660\n",
      "Epoch 3/5\n",
      "15572/15572 [==============================] - 64s 4ms/step - loss: 0.0292 - mean_squared_error: 0.0264 - val_loss: 0.0680 - val_mean_squared_error: 0.0653\n",
      "Epoch 4/5\n",
      "15572/15572 [==============================] - 66s 4ms/step - loss: 0.0293 - mean_squared_error: 0.0267 - val_loss: 0.0703 - val_mean_squared_error: 0.0677\n",
      "Epoch 5/5\n",
      "15572/15572 [==============================] - 67s 4ms/step - loss: 0.0298 - mean_squared_error: 0.0265 - val_loss: 0.0720 - val_mean_squared_error: 0.0696\n",
      "4866/4866 [==============================] - 4s 790us/step\n",
      "model10_combine Loss = 0.0447757169466\n",
      "model10_combine Test Accuracy = 0.0423095524005\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 15572 samples, validate on 3893 samples\n",
      "Epoch 1/5\n",
      "15572/15572 [==============================] - 62s 4ms/step - loss: 0.0284 - mean_squared_error: 0.0261 - val_loss: 0.0712 - val_mean_squared_error: 0.0692\n",
      "Epoch 2/5\n",
      "15572/15572 [==============================] - 65s 4ms/step - loss: 0.0289 - mean_squared_error: 0.0261 - val_loss: 0.0715 - val_mean_squared_error: 0.0690\n",
      "Epoch 3/5\n",
      "15572/15572 [==============================] - 64s 4ms/step - loss: 0.0272 - mean_squared_error: 0.0248 - val_loss: 0.0803 - val_mean_squared_error: 0.0776\n",
      "Epoch 4/5\n",
      "15572/15572 [==============================] - 61s 4ms/step - loss: 0.0282 - mean_squared_error: 0.0254 - val_loss: 0.0678 - val_mean_squared_error: 0.0652\n",
      "Epoch 5/5\n",
      "15572/15572 [==============================] - 64s 4ms/step - loss: 0.0276 - mean_squared_error: 0.0252 - val_loss: 0.0676 - val_mean_squared_error: 0.0651\n",
      "4866/4866 [==============================] - 4s 768us/step\n",
      "model10_combine Loss = 0.0411698441421\n",
      "model10_combine Test Accuracy = 0.038723930715\n",
      "Train on 15572 samples, validate on 3893 samples\n",
      "Epoch 1/5\n",
      "15572/15572 [==============================] - 64s 4ms/step - loss: 0.0264 - mean_squared_error: 0.0241 - val_loss: 0.0688 - val_mean_squared_error: 0.0662\n",
      "Epoch 2/5\n",
      "15572/15572 [==============================] - 65s 4ms/step - loss: 0.0263 - mean_squared_error: 0.0238 - val_loss: 0.0688 - val_mean_squared_error: 0.0667\n",
      "Epoch 3/5\n",
      "15572/15572 [==============================] - 63s 4ms/step - loss: 0.0262 - mean_squared_error: 0.0240 - val_loss: 0.0746 - val_mean_squared_error: 0.0725\n",
      "Epoch 4/5\n",
      "15572/15572 [==============================] - 64s 4ms/step - loss: 0.0284 - mean_squared_error: 0.0257 - val_loss: 0.0703 - val_mean_squared_error: 0.0677\n",
      "Epoch 5/5\n",
      "15572/15572 [==============================] - 63s 4ms/step - loss: 0.0256 - mean_squared_error: 0.0234 - val_loss: 0.0684 - val_mean_squared_error: 0.0667\n",
      "4866/4866 [==============================] - 3s 588us/step\n",
      "model10_combine Loss = 0.0416325170465\n",
      "model10_combine Test Accuracy = 0.0398768678815\n",
      "4866/4866 [==============================] - 3s 570us/step\n",
      "model10_combine Loss = 0.0416325170465\n",
      "model10_combine Test Accuracy = 0.0398768678815\n",
      "[0.041632517046485351, 0.039876867881510979]\n",
      "Train on 15575 samples, validate on 3894 samples\n",
      "Epoch 1/5\n",
      "15575/15575 [==============================] - 71s 5ms/step - loss: 26.2821 - mean_squared_error: 3.2384 - val_loss: 19.0523 - val_mean_squared_error: 0.7068\n",
      "Epoch 2/5\n",
      "15575/15575 [==============================] - 66s 4ms/step - loss: 14.2349 - mean_squared_error: 0.7275 - val_loss: 9.5050 - val_mean_squared_error: 0.3655\n",
      "Epoch 3/5\n",
      "15575/15575 [==============================] - 62s 4ms/step - loss: 6.4062 - mean_squared_error: 0.3831 - val_loss: 3.8296 - val_mean_squared_error: 0.2844\n",
      "Epoch 4/5\n",
      "15575/15575 [==============================] - 62s 4ms/step - loss: 2.4374 - mean_squared_error: 0.3092 - val_loss: 1.3198 - val_mean_squared_error: 0.2245\n",
      "Epoch 5/5\n",
      "15575/15575 [==============================] - 66s 4ms/step - loss: 0.8224 - mean_squared_error: 0.2059 - val_loss: 0.5154 - val_mean_squared_error: 0.2185\n",
      "4862/4862 [==============================] - 3s 610us/step\n",
      "model10_combine Loss = 0.493790620592\n",
      "model10_combine Test Accuracy = 0.196884083459\n",
      "Train on 15575 samples, validate on 3894 samples\n",
      "Epoch 1/5\n",
      "15575/15575 [==============================] - 65s 4ms/step - loss: 0.4344 - mean_squared_error: 0.2153 - val_loss: 0.3216 - val_mean_squared_error: 0.1661\n",
      "Epoch 2/5\n",
      "15575/15575 [==============================] - 63s 4ms/step - loss: 0.4326 - mean_squared_error: 0.2506 - val_loss: 0.3757 - val_mean_squared_error: 0.1964\n",
      "Epoch 3/5\n",
      "15575/15575 [==============================] - 68s 4ms/step - loss: 0.4983 - mean_squared_error: 0.2491 - val_loss: 0.4915 - val_mean_squared_error: 0.1651\n",
      "Epoch 5/5\n",
      "15575/15575 [==============================] - 69s 4ms/step - loss: 0.4323 - mean_squared_error: 0.1752 - val_loss: 0.5307 - val_mean_squared_error: 0.2088\n",
      "4862/4862 [==============================] - 4s 845us/step\n",
      "model10_combine Loss = 0.515567483087\n",
      "model10_combine Test Accuracy = 0.193689015791\n",
      "Train on 15575 samples, validate on 3894 samples\n",
      "Epoch 1/5\n",
      "15575/15575 [==============================] - 69s 4ms/step - loss: 0.3280 - mean_squared_error: 0.1416 - val_loss: 0.3894 - val_mean_squared_error: 0.1650\n",
      "Epoch 2/5\n",
      "15575/15575 [==============================] - 69s 4ms/step - loss: 0.2738 - mean_squared_error: 0.1095 - val_loss: 0.2152 - val_mean_squared_error: 0.1134\n",
      "Epoch 3/5\n",
      "15575/15575 [==============================] - 66s 4ms/step - loss: 0.1839 - mean_squared_error: 0.0902 - val_loss: 0.2189 - val_mean_squared_error: 0.1221\n",
      "Epoch 4/5\n",
      "15575/15575 [==============================] - 69s 4ms/step - loss: 0.1477 - mean_squared_error: 0.0783 - val_loss: 0.1372 - val_mean_squared_error: 0.0872\n",
      "Epoch 5/5\n",
      "15575/15575 [==============================] - 69s 4ms/step - loss: 0.1153 - mean_squared_error: 0.0641 - val_loss: 0.1140 - val_mean_squared_error: 0.0840\n",
      "4862/4862 [==============================] - 2s 512us/step\n",
      "model10_combine Loss = 0.0983058435835\n",
      "model10_combine Test Accuracy = 0.0683083047532\n",
      "Train on 15575 samples, validate on 3894 samples\n",
      "Epoch 1/5\n",
      "15575/15575 [==============================] - 56s 4ms/step - loss: 0.0897 - mean_squared_error: 0.0561 - val_loss: 0.1257 - val_mean_squared_error: 0.0780\n",
      "Epoch 2/5\n",
      "15575/15575 [==============================] - 58s 4ms/step - loss: 0.0839 - mean_squared_error: 0.0526 - val_loss: 0.0962 - val_mean_squared_error: 0.0703\n",
      "Epoch 3/5\n",
      "15575/15575 [==============================] - 61s 4ms/step - loss: 0.0726 - mean_squared_error: 0.0485 - val_loss: 0.0977 - val_mean_squared_error: 0.0759\n",
      "Epoch 4/5\n",
      "15575/15575 [==============================] - 61s 4ms/step - loss: 0.0621 - mean_squared_error: 0.0441 - val_loss: 0.0854 - val_mean_squared_error: 0.0654\n",
      "Epoch 5/5\n",
      "15575/15575 [==============================] - 62s 4ms/step - loss: 0.0588 - mean_squared_error: 0.0436 - val_loss: 0.1002 - val_mean_squared_error: 0.0872\n",
      "4862/4862 [==============================] - 4s 741us/step\n",
      "model10_combine Loss = 0.0720003760006\n",
      "model10_combine Test Accuracy = 0.0590030560212\n",
      "Train on 15575 samples, validate on 3894 samples\n",
      "Epoch 1/5\n",
      "15575/15575 [==============================] - 66s 4ms/step - loss: 0.0549 - mean_squared_error: 0.0430 - val_loss: 0.0945 - val_mean_squared_error: 0.0747\n",
      "Epoch 2/5\n",
      "15575/15575 [==============================] - 66s 4ms/step - loss: 0.0471 - mean_squared_error: 0.0375 - val_loss: 0.0702 - val_mean_squared_error: 0.0637\n",
      "Epoch 3/5\n",
      "15575/15575 [==============================] - 67s 4ms/step - loss: 0.0446 - mean_squared_error: 0.0376 - val_loss: 0.0664 - val_mean_squared_error: 0.0611\n",
      "Epoch 4/5\n",
      "15575/15575 [==============================] - 75s 5ms/step - loss: 0.0423 - mean_squared_error: 0.0366 - val_loss: 0.0752 - val_mean_squared_error: 0.0702\n",
      "Epoch 5/5\n",
      "15575/15575 [==============================] - 74s 5ms/step - loss: 0.0388 - mean_squared_error: 0.0333 - val_loss: 0.0751 - val_mean_squared_error: 0.0676\n",
      "4862/4862 [==============================] - 3s 700us/step\n",
      "model10_combine Loss = 0.0578282663743\n",
      "model10_combine Test Accuracy = 0.0503444242188\n",
      "Train on 15575 samples, validate on 3894 samples\n",
      "Epoch 1/5\n",
      "15575/15575 [==============================] - 71s 5ms/step - loss: 0.0387 - mean_squared_error: 0.0342 - val_loss: 0.0640 - val_mean_squared_error: 0.0601\n",
      "Epoch 2/5\n",
      "15575/15575 [==============================] - 71s 5ms/step - loss: 0.0372 - mean_squared_error: 0.0332 - val_loss: 0.0641 - val_mean_squared_error: 0.0594\n",
      "Epoch 3/5\n",
      "15575/15575 [==============================] - 64s 4ms/step - loss: 0.0373 - mean_squared_error: 0.0331 - val_loss: 0.0822 - val_mean_squared_error: 0.0783\n",
      "Epoch 4/5\n",
      "15575/15575 [==============================] - 68s 4ms/step - loss: 0.0366 - mean_squared_error: 0.0331 - val_loss: 0.0667 - val_mean_squared_error: 0.0636\n",
      "Epoch 5/5\n",
      "15575/15575 [==============================] - 69s 4ms/step - loss: 0.0343 - mean_squared_error: 0.0314 - val_loss: 0.0687 - val_mean_squared_error: 0.0655\n",
      "4862/4862 [==============================] - 4s 754us/step\n",
      "model10_combine Loss = 0.0447695399602\n",
      "model10_combine Test Accuracy = 0.0416085869557\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 15575 samples, validate on 3894 samples\n",
      "Epoch 1/5\n",
      "15575/15575 [==============================] - 69s 4ms/step - loss: 0.0334 - mean_squared_error: 0.0306 - val_loss: 0.0649 - val_mean_squared_error: 0.0627\n",
      "Epoch 2/5\n",
      "15575/15575 [==============================] - 64s 4ms/step - loss: 0.0338 - mean_squared_error: 0.0314 - val_loss: 0.0601 - val_mean_squared_error: 0.0578\n",
      "Epoch 3/5\n",
      "15575/15575 [==============================] - 68s 4ms/step - loss: 0.0313 - mean_squared_error: 0.0292 - val_loss: 0.0624 - val_mean_squared_error: 0.0606\n",
      "Epoch 4/5\n",
      "15575/15575 [==============================] - 69s 4ms/step - loss: 0.0312 - mean_squared_error: 0.0293 - val_loss: 0.0636 - val_mean_squared_error: 0.0619\n",
      "Epoch 5/5\n",
      "15575/15575 [==============================] - 69s 4ms/step - loss: 0.0308 - mean_squared_error: 0.0291 - val_loss: 0.0635 - val_mean_squared_error: 0.0618\n",
      "4862/4862 [==============================] - 4s 773us/step\n",
      "model10_combine Loss = 0.0417463509285\n",
      "model10_combine Test Accuracy = 0.0400668136402\n",
      "Train on 15575 samples, validate on 3894 samples\n",
      "Epoch 1/5\n",
      "15575/15575 [==============================] - 71s 5ms/step - loss: 0.0316 - mean_squared_error: 0.0299 - val_loss: 0.0616 - val_mean_squared_error: 0.0599\n",
      "Epoch 2/5\n",
      "15575/15575 [==============================] - 71s 5ms/step - loss: 0.0289 - mean_squared_error: 0.0273 - val_loss: 0.0644 - val_mean_squared_error: 0.0629\n",
      "Epoch 3/5\n",
      "15575/15575 [==============================] - 68s 4ms/step - loss: 0.0313 - mean_squared_error: 0.0296 - val_loss: 0.0626 - val_mean_squared_error: 0.0609\n",
      "Epoch 4/5\n",
      "15575/15575 [==============================] - 63s 4ms/step - loss: 0.0291 - mean_squared_error: 0.0276 - val_loss: 0.0609 - val_mean_squared_error: 0.0595\n",
      "Epoch 5/5\n",
      "15575/15575 [==============================] - 65s 4ms/step - loss: 0.0283 - mean_squared_error: 0.0269 - val_loss: 0.0605 - val_mean_squared_error: 0.0593\n",
      "4862/4862 [==============================] - 5s 932us/step\n",
      "model10_combine Loss = 0.0405780894368\n",
      "model10_combine Test Accuracy = 0.0393708217115\n",
      "Train on 15575 samples, validate on 3894 samples\n",
      "Epoch 1/5\n",
      "15575/15575 [==============================] - 69s 4ms/step - loss: 0.0285 - mean_squared_error: 0.0272 - val_loss: 0.0653 - val_mean_squared_error: 0.0641\n",
      "Epoch 2/5\n",
      "15575/15575 [==============================] - 73s 5ms/step - loss: 0.0274 - mean_squared_error: 0.0262 - val_loss: 0.0570 - val_mean_squared_error: 0.0558\n",
      "Epoch 3/5\n",
      "15575/15575 [==============================] - 74s 5ms/step - loss: 0.0278 - mean_squared_error: 0.0266 - val_loss: 0.0713 - val_mean_squared_error: 0.0700\n",
      "Epoch 4/5\n",
      "15575/15575 [==============================] - 75s 5ms/step - loss: 0.0285 - mean_squared_error: 0.0272 - val_loss: 0.0625 - val_mean_squared_error: 0.0612\n",
      "Epoch 5/5\n",
      "15575/15575 [==============================] - 75s 5ms/step - loss: 0.0269 - mean_squared_error: 0.0256 - val_loss: 0.0634 - val_mean_squared_error: 0.0622\n",
      "4862/4862 [==============================] - 5s 1ms/step\n",
      "model10_combine Loss = 0.0421493313877\n",
      "model10_combine Test Accuracy = 0.0409497670923\n",
      "Train on 15575 samples, validate on 3894 samples\n",
      "Epoch 1/5\n",
      "15575/15575 [==============================] - 68s 4ms/step - loss: 0.0266 - mean_squared_error: 0.0254 - val_loss: 0.0615 - val_mean_squared_error: 0.0603\n",
      "Epoch 2/5\n",
      "12688/15575 [=======================>......] - ETA: 11s - loss: 0.0268 - mean_squared_error: 0.0256- ETA: 14s"
     ]
    }
   ],
   "source": [
    "i = 0\n",
    "for train, test in kfold.split(stores, origin_y):\n",
    "    if i <= 2:\n",
    "        i += 1\n",
    "        continue\n",
    "    model10_stores, instore = ResNet50(input_shape=stores.shape[1:])\n",
    "    model10_roads, inroad = ResNet50(input_shape=roads.shape[1:])\n",
    "    model10_pois, in3poi = ResNet50(input_shape=pois.shape[1:])\n",
    "    \n",
    "    model10_combine = Three_ResNet(model10_stores, model10_roads, model10_pois, [instore, inroad, in3poi])\n",
    "    model10_combine.compile(optimizer='adam', loss='mse', metrics=['mse'])\n",
    "    for _ in range(10):\n",
    "        lines10_combine = model10_combine.fit([stores[train], roads[train], pois[train]], y_data[train], epochs = 5, batch_size = 16, validation_split=0.2)\n",
    "        preds10_combine_ = model10_combine.evaluate([stores[test], roads[test], pois[test]], y_data[test])\n",
    "        print (\"model10_combine Loss = \" + str(preds10_combine_[0]))\n",
    "        print (\"model10_combine Test Accuracy = \" + str(preds10_combine_[1]))\n",
    "        \n",
    "    preds10_combine = model10_combine.evaluate([stores[test], roads[test], pois[test]], y_data[test])\n",
    "    print (\"model10_combine Loss = \" + str(preds10_combine[0]))\n",
    "    print (\"model10_combine Test Accuracy = \" + str(preds10_combine[1]))\n",
    "    print(preds10_combine)\n",
    "    cvscores.append(preds10_combine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.22232312577059199"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cvrmse = np.mean(np.sqrt(np.asarray(cvscores)[:, 1]))\n",
    "cvrmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 15569 samples, validate on 3893 samples\n",
      "Epoch 1/50\n",
      "15569/15569 [==============================] - 93s 6ms/step - loss: 22.5843 - mean_squared_error: 1.4465 - val_loss: 16.5381 - val_mean_squared_error: 1.7199\n",
      "Epoch 2/50\n",
      "15569/15569 [==============================] - 73s 5ms/step - loss: 10.4134 - mean_squared_error: 0.4796 - val_loss: 6.2208 - val_mean_squared_error: 0.3534\n",
      "Epoch 3/50\n",
      "15569/15569 [==============================] - 71s 5ms/step - loss: 3.9632 - mean_squared_error: 0.3604 - val_loss: 2.1548 - val_mean_squared_error: 0.2657\n",
      "Epoch 4/50\n",
      "15569/15569 [==============================] - 72s 5ms/step - loss: 1.2880 - mean_squared_error: 0.2198 - val_loss: 0.8597 - val_mean_squared_error: 0.3460\n",
      "Epoch 5/50\n",
      "15569/15569 [==============================] - 72s 5ms/step - loss: 0.4901 - mean_squared_error: 0.1805 - val_loss: 0.3894 - val_mean_squared_error: 0.2387\n",
      "Epoch 6/50\n",
      "15569/15569 [==============================] - 71s 5ms/step - loss: 0.2487 - mean_squared_error: 0.1423 - val_loss: 0.2911 - val_mean_squared_error: 0.1734\n",
      "Epoch 7/50\n",
      "15569/15569 [==============================] - 74s 5ms/step - loss: 0.2230 - mean_squared_error: 0.1361 - val_loss: 0.5429 - val_mean_squared_error: 0.4535\n",
      "Epoch 8/50\n",
      "15569/15569 [==============================] - 73s 5ms/step - loss: 0.2194 - mean_squared_error: 0.1290 - val_loss: 0.3458 - val_mean_squared_error: 0.2337\n",
      "Epoch 9/50\n",
      "15569/15569 [==============================] - 72s 5ms/step - loss: 0.2524 - mean_squared_error: 0.1412 - val_loss: 0.2488 - val_mean_squared_error: 0.1668\n",
      "Epoch 10/50\n",
      "15569/15569 [==============================] - 72s 5ms/step - loss: 0.2296 - mean_squared_error: 0.1143 - val_loss: 0.2231 - val_mean_squared_error: 0.1531\n",
      "Epoch 11/50\n",
      "15569/15569 [==============================] - 72s 5ms/step - loss: 0.2422 - mean_squared_error: 0.1186 - val_loss: 0.4887 - val_mean_squared_error: 0.1841\n",
      "Epoch 12/50\n",
      "15569/15569 [==============================] - 80s 5ms/step - loss: 0.2363 - mean_squared_error: 0.1152 - val_loss: 0.3920 - val_mean_squared_error: 0.3172\n",
      "Epoch 13/50\n",
      "15569/15569 [==============================] - 83s 5ms/step - loss: 0.1443 - mean_squared_error: 0.0832 - val_loss: 0.1963 - val_mean_squared_error: 0.1333\n",
      "Epoch 14/50\n",
      "15569/15569 [==============================] - 83s 5ms/step - loss: 0.1304 - mean_squared_error: 0.0778 - val_loss: 0.1593 - val_mean_squared_error: 0.1166\n",
      "Epoch 15/50\n",
      "15569/15569 [==============================] - 83s 5ms/step - loss: 0.1199 - mean_squared_error: 0.0727 - val_loss: 0.1764 - val_mean_squared_error: 0.1481\n",
      "Epoch 16/50\n",
      "15569/15569 [==============================] - 87s 6ms/step - loss: 0.1076 - mean_squared_error: 0.0687 - val_loss: 0.1304 - val_mean_squared_error: 0.0951\n",
      "Epoch 17/50\n",
      "15569/15569 [==============================] - 75s 5ms/step - loss: 0.0860 - mean_squared_error: 0.0600 - val_loss: 0.1387 - val_mean_squared_error: 0.1036\n",
      "Epoch 18/50\n",
      "15569/15569 [==============================] - 90s 6ms/step - loss: 0.0879 - mean_squared_error: 0.0598 - val_loss: 0.1053 - val_mean_squared_error: 0.0834\n",
      "Epoch 19/50\n",
      "15569/15569 [==============================] - 81s 5ms/step - loss: 0.0735 - mean_squared_error: 0.0544 - val_loss: 0.1105 - val_mean_squared_error: 0.0876\n",
      "Epoch 20/50\n",
      "15569/15569 [==============================] - 86s 6ms/step - loss: 0.0700 - mean_squared_error: 0.0517 - val_loss: 0.1022 - val_mean_squared_error: 0.0842\n",
      "Epoch 21/50\n",
      "15569/15569 [==============================] - 73s 5ms/step - loss: 0.0668 - mean_squared_error: 0.0513 - val_loss: 0.1505 - val_mean_squared_error: 0.1347\n",
      "Epoch 22/50\n",
      "15569/15569 [==============================] - 85s 5ms/step - loss: 0.0606 - mean_squared_error: 0.0469 - val_loss: 0.0967 - val_mean_squared_error: 0.0842\n",
      "Epoch 23/50\n",
      "15569/15569 [==============================] - 87s 6ms/step - loss: 0.0604 - mean_squared_error: 0.0477 - val_loss: 0.1050 - val_mean_squared_error: 0.0940\n",
      "Epoch 24/50\n",
      "15569/15569 [==============================] - 79s 5ms/step - loss: 0.0526 - mean_squared_error: 0.0431 - val_loss: 0.0850 - val_mean_squared_error: 0.0772\n",
      "Epoch 25/50\n",
      "15569/15569 [==============================] - 75s 5ms/step - loss: 0.0516 - mean_squared_error: 0.0426 - val_loss: 0.1176 - val_mean_squared_error: 0.1037\n",
      "Epoch 26/50\n",
      "15569/15569 [==============================] - 74s 5ms/step - loss: 0.0503 - mean_squared_error: 0.0416 - val_loss: 0.0840 - val_mean_squared_error: 0.0781\n",
      "Epoch 27/50\n",
      "15569/15569 [==============================] - 74s 5ms/step - loss: 0.0486 - mean_squared_error: 0.0402 - val_loss: 0.0823 - val_mean_squared_error: 0.0757\n",
      "Epoch 28/50\n",
      "15569/15569 [==============================] - 79s 5ms/step - loss: 0.0418 - mean_squared_error: 0.0361 - val_loss: 0.1175 - val_mean_squared_error: 0.1127\n",
      "Epoch 29/50\n",
      "15569/15569 [==============================] - 86s 6ms/step - loss: 0.0467 - mean_squared_error: 0.0391 - val_loss: 0.0949 - val_mean_squared_error: 0.0885\n",
      "Epoch 30/50\n",
      "15569/15569 [==============================] - 81s 5ms/step - loss: 0.0425 - mean_squared_error: 0.0369 - val_loss: 0.0890 - val_mean_squared_error: 0.0827\n",
      "Epoch 31/50\n",
      "15569/15569 [==============================] - 74s 5ms/step - loss: 0.0404 - mean_squared_error: 0.0350 - val_loss: 0.0812 - val_mean_squared_error: 0.0746\n",
      "Epoch 32/50\n",
      "15569/15569 [==============================] - 75s 5ms/step - loss: 0.0422 - mean_squared_error: 0.0361 - val_loss: 0.0838 - val_mean_squared_error: 0.0791\n",
      "Epoch 33/50\n",
      "15569/15569 [==============================] - 76s 5ms/step - loss: 0.0405 - mean_squared_error: 0.0352 - val_loss: 0.1025 - val_mean_squared_error: 0.0965\n",
      "Epoch 34/50\n",
      "15569/15569 [==============================] - 75s 5ms/step - loss: 0.0411 - mean_squared_error: 0.0354 - val_loss: 0.0804 - val_mean_squared_error: 0.0753\n",
      "Epoch 35/50\n",
      "15569/15569 [==============================] - 75s 5ms/step - loss: 0.0392 - mean_squared_error: 0.0333 - val_loss: 0.1281 - val_mean_squared_error: 0.1236\n",
      "Epoch 36/50\n",
      "15569/15569 [==============================] - 75s 5ms/step - loss: 0.0383 - mean_squared_error: 0.0326 - val_loss: 0.0834 - val_mean_squared_error: 0.0779\n",
      "Epoch 37/50\n",
      "15569/15569 [==============================] - 76s 5ms/step - loss: 0.0357 - mean_squared_error: 0.0313 - val_loss: 0.0880 - val_mean_squared_error: 0.0839\n",
      "Epoch 38/50\n",
      "15569/15569 [==============================] - 75s 5ms/step - loss: 0.0352 - mean_squared_error: 0.0314 - val_loss: 0.0681 - val_mean_squared_error: 0.0649\n",
      "Epoch 39/50\n",
      "15569/15569 [==============================] - 76s 5ms/step - loss: 0.0350 - mean_squared_error: 0.0313 - val_loss: 0.0752 - val_mean_squared_error: 0.0715\n",
      "Epoch 40/50\n",
      "15569/15569 [==============================] - 76s 5ms/step - loss: 0.0351 - mean_squared_error: 0.0314 - val_loss: 0.0721 - val_mean_squared_error: 0.0689\n",
      "Epoch 41/50\n",
      "15569/15569 [==============================] - 76s 5ms/step - loss: 0.0342 - mean_squared_error: 0.0302 - val_loss: 0.0715 - val_mean_squared_error: 0.0672\n",
      "Epoch 42/50\n",
      "15569/15569 [==============================] - 77s 5ms/step - loss: 0.0323 - mean_squared_error: 0.0290 - val_loss: 0.0717 - val_mean_squared_error: 0.0686\n",
      "Epoch 43/50\n",
      "15569/15569 [==============================] - 76s 5ms/step - loss: 0.0363 - mean_squared_error: 0.0311 - val_loss: 0.0712 - val_mean_squared_error: 0.0673\n",
      "Epoch 44/50\n",
      "15569/15569 [==============================] - 76s 5ms/step - loss: 0.0330 - mean_squared_error: 0.0294 - val_loss: 0.0923 - val_mean_squared_error: 0.0887\n",
      "Epoch 45/50\n",
      "15569/15569 [==============================] - 76s 5ms/step - loss: 0.0335 - mean_squared_error: 0.0292 - val_loss: 0.0832 - val_mean_squared_error: 0.0789\n",
      "Epoch 46/50\n",
      "15569/15569 [==============================] - 75s 5ms/step - loss: 0.0341 - mean_squared_error: 0.0303 - val_loss: 0.0749 - val_mean_squared_error: 0.0718\n",
      "Epoch 47/50\n",
      "15569/15569 [==============================] - 74s 5ms/step - loss: 0.0306 - mean_squared_error: 0.0277 - val_loss: 0.0769 - val_mean_squared_error: 0.0740\n",
      "Epoch 48/50\n",
      "15569/15569 [==============================] - 75s 5ms/step - loss: 0.0310 - mean_squared_error: 0.0281 - val_loss: 0.0714 - val_mean_squared_error: 0.0681\n",
      "Epoch 49/50\n",
      "15569/15569 [==============================] - 72s 5ms/step - loss: 0.0337 - mean_squared_error: 0.0299 - val_loss: 0.0706 - val_mean_squared_error: 0.0671\n",
      "Epoch 50/50\n",
      "15569/15569 [==============================] - 74s 5ms/step - loss: 0.0312 - mean_squared_error: 0.0282 - val_loss: 0.0818 - val_mean_squared_error: 0.0782\n",
      "4869/4869 [==============================] - 7s 1ms/step\n",
      "model10_combine Loss = 0.0509711673424\n",
      "model10_combine Test Accuracy = 0.0473862681051\n",
      "[0.050971167342433954, 0.047386268105106932]\n",
      "Train on 15571 samples, validate on 3893 samples\n",
      "Epoch 1/50\n",
      "15571/15571 [==============================] - 104s 7ms/step - loss: 23.0103 - mean_squared_error: 1.5178 - val_loss: 16.6894 - val_mean_squared_error: 1.1857\n",
      "Epoch 2/50\n",
      "15571/15571 [==============================] - 76s 5ms/step - loss: 11.1567 - mean_squared_error: 0.5189 - val_loss: 6.9647 - val_mean_squared_error: 0.3301\n",
      "Epoch 3/50\n",
      "15571/15571 [==============================] - 74s 5ms/step - loss: 4.5807 - mean_squared_error: 0.3522 - val_loss: 2.6812 - val_mean_squared_error: 0.2754\n",
      "Epoch 4/50\n",
      "15571/15571 [==============================] - 74s 5ms/step - loss: 1.7024 - mean_squared_error: 0.2523 - val_loss: 1.0469 - val_mean_squared_error: 0.2690\n",
      "Epoch 5/50\n",
      "15571/15571 [==============================] - 76s 5ms/step - loss: 0.6363 - mean_squared_error: 0.1788 - val_loss: 0.4731 - val_mean_squared_error: 0.2266\n",
      "Epoch 6/50\n",
      "15571/15571 [==============================] - 74s 5ms/step - loss: 0.3401 - mean_squared_error: 0.1744 - val_loss: 0.3327 - val_mean_squared_error: 0.1862\n",
      "Epoch 7/50\n",
      "15571/15571 [==============================] - 72s 5ms/step - loss: 0.2293 - mean_squared_error: 0.1369 - val_loss: 0.4287 - val_mean_squared_error: 0.3435\n",
      "Epoch 8/50\n",
      "15571/15571 [==============================] - 72s 5ms/step - loss: 0.2065 - mean_squared_error: 0.1237 - val_loss: 0.2232 - val_mean_squared_error: 0.1545\n",
      "Epoch 9/50\n",
      "15571/15571 [==============================] - 73s 5ms/step - loss: 0.2025 - mean_squared_error: 0.1195 - val_loss: 0.2300 - val_mean_squared_error: 0.1354\n",
      "Epoch 10/50\n",
      "15571/15571 [==============================] - 72s 5ms/step - loss: 0.1802 - mean_squared_error: 0.1079 - val_loss: 0.3805 - val_mean_squared_error: 0.3046\n",
      "Epoch 11/50\n",
      "15571/15571 [==============================] - 72s 5ms/step - loss: 0.1590 - mean_squared_error: 0.0942 - val_loss: 0.1519 - val_mean_squared_error: 0.0930\n",
      "Epoch 12/50\n",
      "15571/15571 [==============================] - 72s 5ms/step - loss: 0.1528 - mean_squared_error: 0.0866 - val_loss: 0.1968 - val_mean_squared_error: 0.1114\n",
      "Epoch 13/50\n",
      "15571/15571 [==============================] - 73s 5ms/step - loss: 0.1324 - mean_squared_error: 0.0759 - val_loss: 0.1969 - val_mean_squared_error: 0.1278\n",
      "Epoch 14/50\n",
      "15571/15571 [==============================] - 72s 5ms/step - loss: 0.1242 - mean_squared_error: 0.0671 - val_loss: 0.1449 - val_mean_squared_error: 0.0971\n",
      "Epoch 15/50\n",
      "15571/15571 [==============================] - 72s 5ms/step - loss: 0.0981 - mean_squared_error: 0.0579 - val_loss: 0.1030 - val_mean_squared_error: 0.0757\n",
      "Epoch 16/50\n",
      "15571/15571 [==============================] - 73s 5ms/step - loss: 0.0978 - mean_squared_error: 0.0551 - val_loss: 0.0922 - val_mean_squared_error: 0.0701\n",
      "Epoch 17/50\n",
      "15571/15571 [==============================] - 73s 5ms/step - loss: 0.0796 - mean_squared_error: 0.0499 - val_loss: 0.1563 - val_mean_squared_error: 0.1152\n",
      "Epoch 18/50\n",
      "15571/15571 [==============================] - 73s 5ms/step - loss: 0.0711 - mean_squared_error: 0.0490 - val_loss: 0.1307 - val_mean_squared_error: 0.1096\n",
      "Epoch 19/50\n",
      "15571/15571 [==============================] - 73s 5ms/step - loss: 0.0627 - mean_squared_error: 0.0445 - val_loss: 0.0852 - val_mean_squared_error: 0.0740\n",
      "Epoch 20/50\n",
      "15571/15571 [==============================] - 73s 5ms/step - loss: 0.0598 - mean_squared_error: 0.0436 - val_loss: 0.1024 - val_mean_squared_error: 0.0865\n",
      "Epoch 21/50\n",
      "15571/15571 [==============================] - 73s 5ms/step - loss: 0.0518 - mean_squared_error: 0.0407 - val_loss: 0.0906 - val_mean_squared_error: 0.0779\n",
      "Epoch 22/50\n",
      "15571/15571 [==============================] - 73s 5ms/step - loss: 0.0510 - mean_squared_error: 0.0397 - val_loss: 0.0760 - val_mean_squared_error: 0.0642\n",
      "Epoch 23/50\n",
      "15571/15571 [==============================] - 73s 5ms/step - loss: 0.0470 - mean_squared_error: 0.0389 - val_loss: 0.0729 - val_mean_squared_error: 0.0664\n",
      "Epoch 24/50\n",
      "15571/15571 [==============================] - 73s 5ms/step - loss: 0.0439 - mean_squared_error: 0.0372 - val_loss: 0.0710 - val_mean_squared_error: 0.0631\n",
      "Epoch 25/50\n",
      "15571/15571 [==============================] - 73s 5ms/step - loss: 0.0415 - mean_squared_error: 0.0358 - val_loss: 0.0708 - val_mean_squared_error: 0.0660\n",
      "Epoch 26/50\n",
      "15571/15571 [==============================] - 73s 5ms/step - loss: 0.0432 - mean_squared_error: 0.0369 - val_loss: 0.0705 - val_mean_squared_error: 0.0654\n",
      "Epoch 27/50\n",
      "15571/15571 [==============================] - 74s 5ms/step - loss: 0.0387 - mean_squared_error: 0.0335 - val_loss: 0.0761 - val_mean_squared_error: 0.0700\n",
      "Epoch 28/50\n",
      "15571/15571 [==============================] - 73s 5ms/step - loss: 0.0394 - mean_squared_error: 0.0342 - val_loss: 0.0733 - val_mean_squared_error: 0.0673\n",
      "Epoch 29/50\n",
      "15571/15571 [==============================] - 74s 5ms/step - loss: 0.0359 - mean_squared_error: 0.0320 - val_loss: 0.0673 - val_mean_squared_error: 0.0640\n",
      "Epoch 30/50\n",
      "15571/15571 [==============================] - 73s 5ms/step - loss: 0.0406 - mean_squared_error: 0.0344 - val_loss: 0.0752 - val_mean_squared_error: 0.0707\n",
      "Epoch 31/50\n",
      "15571/15571 [==============================] - 74s 5ms/step - loss: 0.0362 - mean_squared_error: 0.0324 - val_loss: 0.0705 - val_mean_squared_error: 0.0678\n",
      "Epoch 32/50\n",
      "15571/15571 [==============================] - 74s 5ms/step - loss: 0.0351 - mean_squared_error: 0.0315 - val_loss: 0.0749 - val_mean_squared_error: 0.0715\n",
      "Epoch 33/50\n",
      "15571/15571 [==============================] - 73s 5ms/step - loss: 0.0362 - mean_squared_error: 0.0321 - val_loss: 0.0725 - val_mean_squared_error: 0.0689\n",
      "Epoch 34/50\n",
      "15571/15571 [==============================] - 73s 5ms/step - loss: 0.0340 - mean_squared_error: 0.0306 - val_loss: 0.0742 - val_mean_squared_error: 0.0684\n",
      "Epoch 35/50\n",
      "15571/15571 [==============================] - 73s 5ms/step - loss: 0.0326 - mean_squared_error: 0.0294 - val_loss: 0.0717 - val_mean_squared_error: 0.0685\n",
      "Epoch 36/50\n",
      "15571/15571 [==============================] - 73s 5ms/step - loss: 0.0333 - mean_squared_error: 0.0303 - val_loss: 0.0636 - val_mean_squared_error: 0.0608\n",
      "Epoch 37/50\n",
      "15571/15571 [==============================] - 74s 5ms/step - loss: 0.0331 - mean_squared_error: 0.0300 - val_loss: 0.0628 - val_mean_squared_error: 0.0602\n",
      "Epoch 38/50\n",
      "15571/15571 [==============================] - 74s 5ms/step - loss: 0.0307 - mean_squared_error: 0.0280 - val_loss: 0.0649 - val_mean_squared_error: 0.0625\n",
      "Epoch 39/50\n",
      "15571/15571 [==============================] - 74s 5ms/step - loss: 0.0325 - mean_squared_error: 0.0295 - val_loss: 0.0708 - val_mean_squared_error: 0.0677\n",
      "Epoch 40/50\n",
      "15571/15571 [==============================] - 74s 5ms/step - loss: 0.0321 - mean_squared_error: 0.0291 - val_loss: 0.0694 - val_mean_squared_error: 0.0638\n",
      "Epoch 41/50\n",
      "15571/15571 [==============================] - 74s 5ms/step - loss: 0.0307 - mean_squared_error: 0.0279 - val_loss: 0.0655 - val_mean_squared_error: 0.0627\n",
      "Epoch 42/50\n",
      "15571/15571 [==============================] - 74s 5ms/step - loss: 0.0307 - mean_squared_error: 0.0278 - val_loss: 0.0637 - val_mean_squared_error: 0.0613\n",
      "Epoch 43/50\n",
      "15571/15571 [==============================] - 74s 5ms/step - loss: 0.0304 - mean_squared_error: 0.0278 - val_loss: 0.0633 - val_mean_squared_error: 0.0611\n",
      "Epoch 44/50\n",
      "15571/15571 [==============================] - 75s 5ms/step - loss: 0.0318 - mean_squared_error: 0.0287 - val_loss: 0.0668 - val_mean_squared_error: 0.0639\n",
      "Epoch 45/50\n",
      "15571/15571 [==============================] - 75s 5ms/step - loss: 0.0295 - mean_squared_error: 0.0269 - val_loss: 0.0618 - val_mean_squared_error: 0.0594\n",
      "Epoch 46/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15571/15571 [==============================] - 71s 5ms/step - loss: 0.0289 - mean_squared_error: 0.0267 - val_loss: 0.0737 - val_mean_squared_error: 0.0718\n",
      "Epoch 47/50\n",
      "15571/15571 [==============================] - 71s 5ms/step - loss: 0.0292 - mean_squared_error: 0.0269 - val_loss: 0.0701 - val_mean_squared_error: 0.0684\n",
      "Epoch 48/50\n",
      "15571/15571 [==============================] - 71s 5ms/step - loss: 0.0286 - mean_squared_error: 0.0265 - val_loss: 0.0638 - val_mean_squared_error: 0.0619\n",
      "Epoch 49/50\n",
      "15571/15571 [==============================] - 72s 5ms/step - loss: 0.0285 - mean_squared_error: 0.0264 - val_loss: 0.0668 - val_mean_squared_error: 0.0637\n",
      "Epoch 50/50\n",
      "15571/15571 [==============================] - 72s 5ms/step - loss: 0.0282 - mean_squared_error: 0.0259 - val_loss: 0.0669 - val_mean_squared_error: 0.0650\n",
      "4867/4867 [==============================] - 7s 1ms/step\n",
      "model10_combine Loss = 0.0467052270536\n",
      "model10_combine Test Accuracy = 0.0448326347777\n",
      "[0.046705227053603866, 0.044832634777657324]\n",
      "Train on 15571 samples, validate on 3893 samples\n",
      "Epoch 1/50\n",
      "15571/15571 [==============================] - 93s 6ms/step - loss: 22.6284 - mean_squared_error: 1.4461 - val_loss: 15.4519 - val_mean_squared_error: 0.5893\n",
      "Epoch 2/50\n",
      "15571/15571 [==============================] - 72s 5ms/step - loss: 10.2735 - mean_squared_error: 0.4889 - val_loss: 6.9746 - val_mean_squared_error: 1.2459\n",
      "Epoch 3/50\n",
      "15571/15571 [==============================] - 73s 5ms/step - loss: 3.8204 - mean_squared_error: 0.3762 - val_loss: 2.1395 - val_mean_squared_error: 0.3603\n",
      "Epoch 4/50\n",
      "15571/15571 [==============================] - 72s 5ms/step - loss: 1.2067 - mean_squared_error: 0.2210 - val_loss: 0.6541 - val_mean_squared_error: 0.1863\n",
      "Epoch 5/50\n",
      "15571/15571 [==============================] - 73s 5ms/step - loss: 0.4292 - mean_squared_error: 0.1665 - val_loss: 0.4896 - val_mean_squared_error: 0.3345\n",
      "Epoch 6/50\n",
      "15571/15571 [==============================] - 73s 5ms/step - loss: 0.2535 - mean_squared_error: 0.1423 - val_loss: 0.1957 - val_mean_squared_error: 0.1312\n",
      "Epoch 7/50\n",
      "15571/15571 [==============================] - 73s 5ms/step - loss: 0.1812 - mean_squared_error: 0.1169 - val_loss: 0.3198 - val_mean_squared_error: 0.2603\n",
      "Epoch 8/50\n",
      "15571/15571 [==============================] - 73s 5ms/step - loss: 0.1993 - mean_squared_error: 0.1278 - val_loss: 0.2277 - val_mean_squared_error: 0.1626\n",
      "Epoch 9/50\n",
      "15571/15571 [==============================] - 73s 5ms/step - loss: 0.1922 - mean_squared_error: 0.1201 - val_loss: 0.1651 - val_mean_squared_error: 0.1127\n",
      "Epoch 10/50\n",
      "15571/15571 [==============================] - 73s 5ms/step - loss: 0.1863 - mean_squared_error: 0.0988 - val_loss: 0.1903 - val_mean_squared_error: 0.1228\n",
      "Epoch 11/50\n",
      "15571/15571 [==============================] - 74s 5ms/step - loss: 0.1766 - mean_squared_error: 0.0959 - val_loss: 0.3287 - val_mean_squared_error: 0.2613\n",
      "Epoch 12/50\n",
      "15571/15571 [==============================] - 73s 5ms/step - loss: 0.1764 - mean_squared_error: 0.0876 - val_loss: 0.2197 - val_mean_squared_error: 0.1322\n",
      "Epoch 13/50\n",
      "15571/15571 [==============================] - 73s 5ms/step - loss: 0.1256 - mean_squared_error: 0.0685 - val_loss: 0.1403 - val_mean_squared_error: 0.0973\n",
      "Epoch 14/50\n",
      "15571/15571 [==============================] - 73s 5ms/step - loss: 0.1114 - mean_squared_error: 0.0621 - val_loss: 0.2330 - val_mean_squared_error: 0.1324\n",
      "Epoch 15/50\n",
      "15571/15571 [==============================] - 73s 5ms/step - loss: 0.1000 - mean_squared_error: 0.0565 - val_loss: 0.1343 - val_mean_squared_error: 0.0985\n",
      "Epoch 16/50\n",
      "15571/15571 [==============================] - 73s 5ms/step - loss: 0.1019 - mean_squared_error: 0.0577 - val_loss: 0.2618 - val_mean_squared_error: 0.0940\n",
      "Epoch 17/50\n",
      "15571/15571 [==============================] - 73s 5ms/step - loss: 0.0848 - mean_squared_error: 0.0492 - val_loss: 0.1557 - val_mean_squared_error: 0.1225\n",
      "Epoch 18/50\n",
      "15571/15571 [==============================] - 73s 5ms/step - loss: 0.0648 - mean_squared_error: 0.0456 - val_loss: 0.0900 - val_mean_squared_error: 0.0727\n",
      "Epoch 19/50\n",
      "15571/15571 [==============================] - 73s 5ms/step - loss: 0.0782 - mean_squared_error: 0.0437 - val_loss: 0.1123 - val_mean_squared_error: 0.0940\n",
      "Epoch 20/50\n",
      "15571/15571 [==============================] - 79s 5ms/step - loss: 0.0536 - mean_squared_error: 0.0395 - val_loss: 0.0900 - val_mean_squared_error: 0.0761\n",
      "Epoch 21/50\n",
      "15571/15571 [==============================] - 81s 5ms/step - loss: 0.0537 - mean_squared_error: 0.0396 - val_loss: 0.0882 - val_mean_squared_error: 0.0694\n",
      "Epoch 22/50\n",
      "15571/15571 [==============================] - 73s 5ms/step - loss: 0.0508 - mean_squared_error: 0.0392 - val_loss: 0.0938 - val_mean_squared_error: 0.0791\n",
      "Epoch 23/50\n",
      "15571/15571 [==============================] - 73s 5ms/step - loss: 0.0463 - mean_squared_error: 0.0371 - val_loss: 0.1053 - val_mean_squared_error: 0.0988\n",
      "Epoch 24/50\n",
      "15571/15571 [==============================] - 73s 5ms/step - loss: 0.0440 - mean_squared_error: 0.0362 - val_loss: 0.0808 - val_mean_squared_error: 0.0691\n",
      "Epoch 25/50\n",
      "15571/15571 [==============================] - 73s 5ms/step - loss: 0.0408 - mean_squared_error: 0.0339 - val_loss: 0.0789 - val_mean_squared_error: 0.0739\n",
      "Epoch 26/50\n",
      "15571/15571 [==============================] - 73s 5ms/step - loss: 0.0405 - mean_squared_error: 0.0336 - val_loss: 0.0737 - val_mean_squared_error: 0.0691\n",
      "Epoch 27/50\n",
      "15571/15571 [==============================] - 73s 5ms/step - loss: 0.0386 - mean_squared_error: 0.0331 - val_loss: 0.0723 - val_mean_squared_error: 0.0682\n",
      "Epoch 28/50\n",
      "15571/15571 [==============================] - 73s 5ms/step - loss: 0.0354 - mean_squared_error: 0.0308 - val_loss: 0.0748 - val_mean_squared_error: 0.0706\n",
      "Epoch 29/50\n",
      "15571/15571 [==============================] - 73s 5ms/step - loss: 0.0357 - mean_squared_error: 0.0310 - val_loss: 0.0691 - val_mean_squared_error: 0.0649\n",
      "Epoch 30/50\n",
      "15571/15571 [==============================] - 73s 5ms/step - loss: 0.0352 - mean_squared_error: 0.0302 - val_loss: 0.0692 - val_mean_squared_error: 0.0649\n",
      "Epoch 31/50\n",
      "15571/15571 [==============================] - 73s 5ms/step - loss: 0.0341 - mean_squared_error: 0.0302 - val_loss: 0.0737 - val_mean_squared_error: 0.0690\n",
      "Epoch 32/50\n",
      "15571/15571 [==============================] - 73s 5ms/step - loss: 0.0328 - mean_squared_error: 0.0291 - val_loss: 0.0806 - val_mean_squared_error: 0.0772\n",
      "Epoch 33/50\n",
      "15571/15571 [==============================] - 73s 5ms/step - loss: 0.0306 - mean_squared_error: 0.0275 - val_loss: 0.0768 - val_mean_squared_error: 0.0740\n",
      "Epoch 34/50\n",
      "15571/15571 [==============================] - 73s 5ms/step - loss: 0.0338 - mean_squared_error: 0.0300 - val_loss: 0.0789 - val_mean_squared_error: 0.0742\n",
      "Epoch 35/50\n",
      "15571/15571 [==============================] - 73s 5ms/step - loss: 0.0313 - mean_squared_error: 0.0278 - val_loss: 0.0731 - val_mean_squared_error: 0.0699\n",
      "Epoch 36/50\n",
      "15571/15571 [==============================] - 74s 5ms/step - loss: 0.0299 - mean_squared_error: 0.0271 - val_loss: 0.0681 - val_mean_squared_error: 0.0652\n",
      "Epoch 37/50\n",
      "15571/15571 [==============================] - 73s 5ms/step - loss: 0.0293 - mean_squared_error: 0.0263 - val_loss: 0.0712 - val_mean_squared_error: 0.0683\n",
      "Epoch 38/50\n",
      "15571/15571 [==============================] - 73s 5ms/step - loss: 0.0296 - mean_squared_error: 0.0268 - val_loss: 0.0744 - val_mean_squared_error: 0.0716\n",
      "Epoch 39/50\n",
      "15571/15571 [==============================] - 73s 5ms/step - loss: 0.0296 - mean_squared_error: 0.0266 - val_loss: 0.0674 - val_mean_squared_error: 0.0649\n",
      "Epoch 40/50\n",
      "15571/15571 [==============================] - 74s 5ms/step - loss: 0.0284 - mean_squared_error: 0.0257 - val_loss: 0.0718 - val_mean_squared_error: 0.0692\n",
      "Epoch 41/50\n",
      "15571/15571 [==============================] - 73s 5ms/step - loss: 0.0286 - mean_squared_error: 0.0258 - val_loss: 0.0802 - val_mean_squared_error: 0.0770\n",
      "Epoch 42/50\n",
      "15571/15571 [==============================] - 73s 5ms/step - loss: 0.0281 - mean_squared_error: 0.0251 - val_loss: 0.0711 - val_mean_squared_error: 0.0681\n",
      "Epoch 43/50\n",
      "15571/15571 [==============================] - 72s 5ms/step - loss: 0.0276 - mean_squared_error: 0.0254 - val_loss: 0.0758 - val_mean_squared_error: 0.0738\n",
      "Epoch 44/50\n",
      "15571/15571 [==============================] - 72s 5ms/step - loss: 0.0260 - mean_squared_error: 0.0239 - val_loss: 0.0727 - val_mean_squared_error: 0.0701\n",
      "Epoch 45/50\n",
      "15571/15571 [==============================] - 72s 5ms/step - loss: 0.0268 - mean_squared_error: 0.0245 - val_loss: 0.0694 - val_mean_squared_error: 0.0672\n",
      "Epoch 46/50\n",
      "15571/15571 [==============================] - 72s 5ms/step - loss: 0.0274 - mean_squared_error: 0.0250 - val_loss: 0.0683 - val_mean_squared_error: 0.0663\n",
      "Epoch 47/50\n",
      "15571/15571 [==============================] - 72s 5ms/step - loss: 0.0272 - mean_squared_error: 0.0247 - val_loss: 0.0765 - val_mean_squared_error: 0.0737\n",
      "Epoch 48/50\n",
      "15571/15571 [==============================] - 72s 5ms/step - loss: 0.0261 - mean_squared_error: 0.0238 - val_loss: 0.0701 - val_mean_squared_error: 0.0680\n",
      "Epoch 49/50\n",
      "15571/15571 [==============================] - 72s 5ms/step - loss: 0.0254 - mean_squared_error: 0.0233 - val_loss: 0.0743 - val_mean_squared_error: 0.0719\n",
      "Epoch 50/50\n",
      "15571/15571 [==============================] - 72s 5ms/step - loss: 0.0261 - mean_squared_error: 0.0239 - val_loss: 0.0738 - val_mean_squared_error: 0.0723\n",
      "4867/4867 [==============================] - 7s 2ms/step\n",
      "model10_combine Loss = 0.0548527414013\n",
      "model10_combine Test Accuracy = 0.0533875771914\n",
      "[0.054852741401323381, 0.053387577191396293]\n",
      "Train on 15572 samples, validate on 3893 samples\n",
      "Epoch 1/50\n",
      "15572/15572 [==============================] - 94s 6ms/step - loss: 22.4106 - mean_squared_error: 1.3558 - val_loss: 15.1574 - val_mean_squared_error: 0.5236\n",
      "Epoch 2/50\n",
      "15572/15572 [==============================] - 72s 5ms/step - loss: 10.0345 - mean_squared_error: 0.4978 - val_loss: 5.9168 - val_mean_squared_error: 0.4408\n",
      "Epoch 3/50\n",
      "15572/15572 [==============================] - 72s 5ms/step - loss: 3.5396 - mean_squared_error: 0.3230 - val_loss: 2.0364 - val_mean_squared_error: 0.4202\n",
      "Epoch 4/50\n",
      "15572/15572 [==============================] - 73s 5ms/step - loss: 1.1117 - mean_squared_error: 0.2287 - val_loss: 0.6152 - val_mean_squared_error: 0.2100\n",
      "Epoch 5/50\n",
      "15572/15572 [==============================] - 72s 5ms/step - loss: 0.4051 - mean_squared_error: 0.1723 - val_loss: 0.3799 - val_mean_squared_error: 0.2277\n",
      "Epoch 6/50\n",
      "15572/15572 [==============================] - 72s 5ms/step - loss: 0.2626 - mean_squared_error: 0.1531 - val_loss: 0.4060 - val_mean_squared_error: 0.3380\n",
      "Epoch 7/50\n",
      "15572/15572 [==============================] - 72s 5ms/step - loss: 0.1972 - mean_squared_error: 0.1255 - val_loss: 0.3253 - val_mean_squared_error: 0.2817\n",
      "Epoch 8/50\n",
      "15572/15572 [==============================] - 72s 5ms/step - loss: 0.2145 - mean_squared_error: 0.1302 - val_loss: 0.2097 - val_mean_squared_error: 0.1322\n",
      "Epoch 9/50\n",
      "15572/15572 [==============================] - 72s 5ms/step - loss: 0.1930 - mean_squared_error: 0.1161 - val_loss: 0.2299 - val_mean_squared_error: 0.1644\n",
      "Epoch 10/50\n",
      "15572/15572 [==============================] - 73s 5ms/step - loss: 0.1879 - mean_squared_error: 0.1034 - val_loss: 0.2267 - val_mean_squared_error: 0.1514\n",
      "Epoch 11/50\n",
      "15572/15572 [==============================] - 72s 5ms/step - loss: 0.1799 - mean_squared_error: 0.0969 - val_loss: 0.3984 - val_mean_squared_error: 0.3030\n",
      "Epoch 12/50\n",
      "15572/15572 [==============================] - 72s 5ms/step - loss: 0.1654 - mean_squared_error: 0.0863 - val_loss: 0.1647 - val_mean_squared_error: 0.1221\n",
      "Epoch 13/50\n",
      "15572/15572 [==============================] - 73s 5ms/step - loss: 0.1218 - mean_squared_error: 0.0664 - val_loss: 0.1419 - val_mean_squared_error: 0.1059\n",
      "Epoch 14/50\n",
      "15572/15572 [==============================] - 72s 5ms/step - loss: 0.1002 - mean_squared_error: 0.0601 - val_loss: 0.1555 - val_mean_squared_error: 0.1217\n",
      "Epoch 15/50\n",
      "15572/15572 [==============================] - 72s 5ms/step - loss: 0.0891 - mean_squared_error: 0.0545 - val_loss: 0.1318 - val_mean_squared_error: 0.1076\n",
      "Epoch 16/50\n",
      "15572/15572 [==============================] - 72s 5ms/step - loss: 0.0793 - mean_squared_error: 0.0501 - val_loss: 0.1020 - val_mean_squared_error: 0.0834\n",
      "Epoch 17/50\n",
      "15572/15572 [==============================] - 72s 5ms/step - loss: 0.0778 - mean_squared_error: 0.0499 - val_loss: 0.1168 - val_mean_squared_error: 0.0949\n",
      "Epoch 18/50\n",
      "15572/15572 [==============================] - 72s 5ms/step - loss: 0.0663 - mean_squared_error: 0.0466 - val_loss: 0.1253 - val_mean_squared_error: 0.1008\n",
      "Epoch 19/50\n",
      "15572/15572 [==============================] - 72s 5ms/step - loss: 0.0599 - mean_squared_error: 0.0438 - val_loss: 0.1297 - val_mean_squared_error: 0.1089\n",
      "Epoch 20/50\n",
      "15572/15572 [==============================] - 72s 5ms/step - loss: 0.0534 - mean_squared_error: 0.0404 - val_loss: 0.1196 - val_mean_squared_error: 0.1076\n",
      "Epoch 21/50\n",
      "15572/15572 [==============================] - 72s 5ms/step - loss: 0.0529 - mean_squared_error: 0.0410 - val_loss: 0.0956 - val_mean_squared_error: 0.0870\n",
      "Epoch 22/50\n",
      "15572/15572 [==============================] - 72s 5ms/step - loss: 0.0474 - mean_squared_error: 0.0374 - val_loss: 0.0926 - val_mean_squared_error: 0.0845\n",
      "Epoch 23/50\n",
      "15572/15572 [==============================] - 72s 5ms/step - loss: 0.0456 - mean_squared_error: 0.0370 - val_loss: 0.0873 - val_mean_squared_error: 0.0774\n",
      "Epoch 24/50\n",
      "15572/15572 [==============================] - 72s 5ms/step - loss: 0.0428 - mean_squared_error: 0.0351 - val_loss: 0.0909 - val_mean_squared_error: 0.0838\n",
      "Epoch 25/50\n",
      "15572/15572 [==============================] - 73s 5ms/step - loss: 0.0401 - mean_squared_error: 0.0336 - val_loss: 0.0952 - val_mean_squared_error: 0.0889\n",
      "Epoch 26/50\n",
      "15572/15572 [==============================] - 72s 5ms/step - loss: 0.0390 - mean_squared_error: 0.0332 - val_loss: 0.0866 - val_mean_squared_error: 0.0814\n",
      "Epoch 27/50\n",
      "15572/15572 [==============================] - 72s 5ms/step - loss: 0.0385 - mean_squared_error: 0.0335 - val_loss: 0.0913 - val_mean_squared_error: 0.0851\n",
      "Epoch 28/50\n",
      "15572/15572 [==============================] - 72s 5ms/step - loss: 0.0368 - mean_squared_error: 0.0319 - val_loss: 0.0826 - val_mean_squared_error: 0.0782\n",
      "Epoch 29/50\n",
      "15572/15572 [==============================] - 72s 5ms/step - loss: 0.0349 - mean_squared_error: 0.0308 - val_loss: 0.0836 - val_mean_squared_error: 0.0800\n",
      "Epoch 30/50\n",
      "15572/15572 [==============================] - 72s 5ms/step - loss: 0.0342 - mean_squared_error: 0.0300 - val_loss: 0.0801 - val_mean_squared_error: 0.0761\n",
      "Epoch 31/50\n",
      "15572/15572 [==============================] - 72s 5ms/step - loss: 0.0324 - mean_squared_error: 0.0284 - val_loss: 0.0825 - val_mean_squared_error: 0.0795\n",
      "Epoch 32/50\n",
      "15572/15572 [==============================] - 72s 5ms/step - loss: 0.0333 - mean_squared_error: 0.0298 - val_loss: 0.0864 - val_mean_squared_error: 0.0828\n",
      "Epoch 33/50\n",
      "15572/15572 [==============================] - 73s 5ms/step - loss: 0.0335 - mean_squared_error: 0.0295 - val_loss: 0.0850 - val_mean_squared_error: 0.0812\n",
      "Epoch 34/50\n",
      "15572/15572 [==============================] - 72s 5ms/step - loss: 0.0302 - mean_squared_error: 0.0269 - val_loss: 0.0864 - val_mean_squared_error: 0.0821\n",
      "Epoch 35/50\n",
      "15572/15572 [==============================] - 74s 5ms/step - loss: 0.0329 - mean_squared_error: 0.0290 - val_loss: 0.0847 - val_mean_squared_error: 0.0817\n",
      "Epoch 36/50\n",
      "15572/15572 [==============================] - 73s 5ms/step - loss: 0.0301 - mean_squared_error: 0.0271 - val_loss: 0.0828 - val_mean_squared_error: 0.0805\n",
      "Epoch 37/50\n",
      "15572/15572 [==============================] - 73s 5ms/step - loss: 0.0289 - mean_squared_error: 0.0261 - val_loss: 0.1114 - val_mean_squared_error: 0.1069\n",
      "Epoch 38/50\n",
      "15572/15572 [==============================] - 73s 5ms/step - loss: 0.0314 - mean_squared_error: 0.0280 - val_loss: 0.0845 - val_mean_squared_error: 0.0818\n",
      "Epoch 39/50\n",
      "15572/15572 [==============================] - 72s 5ms/step - loss: 0.0290 - mean_squared_error: 0.0261 - val_loss: 0.0844 - val_mean_squared_error: 0.0822\n",
      "Epoch 40/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15572/15572 [==============================] - 71s 5ms/step - loss: 0.0295 - mean_squared_error: 0.0264 - val_loss: 0.0828 - val_mean_squared_error: 0.0805\n",
      "Epoch 41/50\n",
      "15572/15572 [==============================] - 71s 5ms/step - loss: 0.0295 - mean_squared_error: 0.0267 - val_loss: 0.0823 - val_mean_squared_error: 0.0800\n",
      "Epoch 42/50\n",
      "15572/15572 [==============================] - 71s 5ms/step - loss: 0.0285 - mean_squared_error: 0.0259 - val_loss: 0.0770 - val_mean_squared_error: 0.0745\n",
      "Epoch 43/50\n",
      "15572/15572 [==============================] - 71s 5ms/step - loss: 0.0276 - mean_squared_error: 0.0249 - val_loss: 0.0794 - val_mean_squared_error: 0.0773\n",
      "Epoch 44/50\n",
      "15572/15572 [==============================] - 71s 5ms/step - loss: 0.0272 - mean_squared_error: 0.0249 - val_loss: 0.0817 - val_mean_squared_error: 0.0790\n",
      "Epoch 45/50\n",
      "15572/15572 [==============================] - 71s 5ms/step - loss: 0.0275 - mean_squared_error: 0.0250 - val_loss: 0.0850 - val_mean_squared_error: 0.0823\n",
      "Epoch 46/50\n",
      "15572/15572 [==============================] - 71s 5ms/step - loss: 0.0288 - mean_squared_error: 0.0261 - val_loss: 0.0797 - val_mean_squared_error: 0.0777\n",
      "Epoch 47/50\n",
      "15572/15572 [==============================] - 71s 5ms/step - loss: 0.0261 - mean_squared_error: 0.0239 - val_loss: 0.0787 - val_mean_squared_error: 0.0766\n",
      "Epoch 48/50\n",
      "15572/15572 [==============================] - 71s 5ms/step - loss: 0.0285 - mean_squared_error: 0.0257 - val_loss: 0.0813 - val_mean_squared_error: 0.0790\n",
      "Epoch 49/50\n",
      "15572/15572 [==============================] - 71s 5ms/step - loss: 0.0263 - mean_squared_error: 0.0242 - val_loss: 0.0868 - val_mean_squared_error: 0.0845\n",
      "Epoch 50/50\n",
      "15572/15572 [==============================] - 71s 5ms/step - loss: 0.0259 - mean_squared_error: 0.0237 - val_loss: 0.0857 - val_mean_squared_error: 0.0838\n",
      "4866/4866 [==============================] - 7s 1ms/step\n",
      "model10_combine Loss = 0.0534682713673\n",
      "model10_combine Test Accuracy = 0.0515380333994\n",
      "[0.053468271367254933, 0.051538033399423158]\n",
      "Train on 15575 samples, validate on 3894 samples\n",
      "Epoch 1/50\n",
      "15575/15575 [==============================] - 99s 6ms/step - loss: 22.3226 - mean_squared_error: 1.3295 - val_loss: 15.1658 - val_mean_squared_error: 0.5863\n",
      "Epoch 2/50\n",
      "15575/15575 [==============================] - 73s 5ms/step - loss: 10.1501 - mean_squared_error: 0.5416 - val_loss: 6.0060 - val_mean_squared_error: 0.3445\n",
      "Epoch 3/50\n",
      "15575/15575 [==============================] - 72s 5ms/step - loss: 3.7793 - mean_squared_error: 0.3552 - val_loss: 2.0632 - val_mean_squared_error: 0.2614\n",
      "Epoch 4/50\n",
      "15575/15575 [==============================] - 72s 5ms/step - loss: 1.3142 - mean_squared_error: 0.2762 - val_loss: 0.7105 - val_mean_squared_error: 0.1944\n",
      "Epoch 5/50\n",
      "15575/15575 [==============================] - 72s 5ms/step - loss: 0.5108 - mean_squared_error: 0.2034 - val_loss: 0.3622 - val_mean_squared_error: 0.1901\n",
      "Epoch 6/50\n",
      "15575/15575 [==============================] - 72s 5ms/step - loss: 0.3330 - mean_squared_error: 0.1891 - val_loss: 0.4120 - val_mean_squared_error: 0.3152\n",
      "Epoch 7/50\n",
      "15575/15575 [==============================] - 72s 5ms/step - loss: 0.2885 - mean_squared_error: 0.1788 - val_loss: 0.2506 - val_mean_squared_error: 0.1681\n",
      "Epoch 8/50\n",
      "15575/15575 [==============================] - 72s 5ms/step - loss: 0.2307 - mean_squared_error: 0.1427 - val_loss: 0.2321 - val_mean_squared_error: 0.1598\n",
      "Epoch 9/50\n",
      "15575/15575 [==============================] - 73s 5ms/step - loss: 0.2688 - mean_squared_error: 0.1582 - val_loss: 0.2803 - val_mean_squared_error: 0.2078\n",
      "Epoch 10/50\n",
      "15575/15575 [==============================] - 72s 5ms/step - loss: 0.2373 - mean_squared_error: 0.1372 - val_loss: 0.2994 - val_mean_squared_error: 0.1495\n",
      "Epoch 11/50\n",
      "15575/15575 [==============================] - 72s 5ms/step - loss: 0.2195 - mean_squared_error: 0.1179 - val_loss: 0.2385 - val_mean_squared_error: 0.1518\n",
      "Epoch 12/50\n",
      "15575/15575 [==============================] - 72s 5ms/step - loss: 0.1807 - mean_squared_error: 0.0968 - val_loss: 0.1838 - val_mean_squared_error: 0.1215\n",
      "Epoch 13/50\n",
      "15575/15575 [==============================] - 72s 5ms/step - loss: 0.1553 - mean_squared_error: 0.0842 - val_loss: 0.1957 - val_mean_squared_error: 0.1111\n",
      "Epoch 14/50\n",
      "15575/15575 [==============================] - 72s 5ms/step - loss: 0.1436 - mean_squared_error: 0.0773 - val_loss: 0.1806 - val_mean_squared_error: 0.1241\n",
      "Epoch 15/50\n",
      "15575/15575 [==============================] - 72s 5ms/step - loss: 0.1376 - mean_squared_error: 0.0728 - val_loss: 0.1504 - val_mean_squared_error: 0.1024\n",
      "Epoch 16/50\n",
      "15575/15575 [==============================] - 72s 5ms/step - loss: 0.1173 - mean_squared_error: 0.0669 - val_loss: 0.1171 - val_mean_squared_error: 0.0855\n",
      "Epoch 17/50\n",
      "15575/15575 [==============================] - 72s 5ms/step - loss: 0.0984 - mean_squared_error: 0.0594 - val_loss: 0.1186 - val_mean_squared_error: 0.0804\n",
      "Epoch 18/50\n",
      "15575/15575 [==============================] - 72s 5ms/step - loss: 0.0891 - mean_squared_error: 0.0541 - val_loss: 0.1208 - val_mean_squared_error: 0.0909\n",
      "Epoch 19/50\n",
      "15575/15575 [==============================] - 72s 5ms/step - loss: 0.0744 - mean_squared_error: 0.0487 - val_loss: 0.1041 - val_mean_squared_error: 0.0797\n",
      "Epoch 20/50\n",
      "15575/15575 [==============================] - 72s 5ms/step - loss: 0.0705 - mean_squared_error: 0.0475 - val_loss: 0.0922 - val_mean_squared_error: 0.0767\n",
      "Epoch 21/50\n",
      "15575/15575 [==============================] - 72s 5ms/step - loss: 0.0647 - mean_squared_error: 0.0450 - val_loss: 0.1151 - val_mean_squared_error: 0.0863\n",
      "Epoch 22/50\n",
      "15575/15575 [==============================] - 72s 5ms/step - loss: 0.0614 - mean_squared_error: 0.0441 - val_loss: 0.1228 - val_mean_squared_error: 0.0968\n",
      "Epoch 23/50\n",
      "15575/15575 [==============================] - 72s 5ms/step - loss: 0.0607 - mean_squared_error: 0.0429 - val_loss: 0.0844 - val_mean_squared_error: 0.0673\n",
      "Epoch 24/50\n",
      "15575/15575 [==============================] - 72s 5ms/step - loss: 0.0538 - mean_squared_error: 0.0399 - val_loss: 0.0846 - val_mean_squared_error: 0.0722\n",
      "Epoch 25/50\n",
      "15575/15575 [==============================] - 72s 5ms/step - loss: 0.0502 - mean_squared_error: 0.0373 - val_loss: 0.0985 - val_mean_squared_error: 0.0828\n",
      "Epoch 26/50\n",
      "15575/15575 [==============================] - 72s 5ms/step - loss: 0.0503 - mean_squared_error: 0.0367 - val_loss: 0.0849 - val_mean_squared_error: 0.0712\n",
      "Epoch 27/50\n",
      "15575/15575 [==============================] - 72s 5ms/step - loss: 0.0488 - mean_squared_error: 0.0359 - val_loss: 0.0974 - val_mean_squared_error: 0.0756\n",
      "Epoch 28/50\n",
      "15575/15575 [==============================] - 72s 5ms/step - loss: 0.0526 - mean_squared_error: 0.0372 - val_loss: 0.0784 - val_mean_squared_error: 0.0650\n",
      "Epoch 29/50\n",
      "15575/15575 [==============================] - 72s 5ms/step - loss: 0.0469 - mean_squared_error: 0.0343 - val_loss: 0.0776 - val_mean_squared_error: 0.0661\n",
      "Epoch 30/50\n",
      "15575/15575 [==============================] - 72s 5ms/step - loss: 0.0432 - mean_squared_error: 0.0333 - val_loss: 0.0758 - val_mean_squared_error: 0.0664\n",
      "Epoch 31/50\n",
      "15575/15575 [==============================] - 72s 5ms/step - loss: 0.0404 - mean_squared_error: 0.0326 - val_loss: 0.0849 - val_mean_squared_error: 0.0769\n",
      "Epoch 32/50\n",
      "15575/15575 [==============================] - 72s 5ms/step - loss: 0.0384 - mean_squared_error: 0.0322 - val_loss: 0.0724 - val_mean_squared_error: 0.0681\n",
      "Epoch 33/50\n",
      "15575/15575 [==============================] - 72s 5ms/step - loss: 0.0369 - mean_squared_error: 0.0316 - val_loss: 0.0713 - val_mean_squared_error: 0.0667\n",
      "Epoch 34/50\n",
      "15575/15575 [==============================] - 73s 5ms/step - loss: 0.0358 - mean_squared_error: 0.0311 - val_loss: 0.0721 - val_mean_squared_error: 0.0658\n",
      "Epoch 35/50\n",
      "15575/15575 [==============================] - 72s 5ms/step - loss: 0.0355 - mean_squared_error: 0.0313 - val_loss: 0.0720 - val_mean_squared_error: 0.0669\n",
      "Epoch 36/50\n",
      "15575/15575 [==============================] - 72s 5ms/step - loss: 0.0333 - mean_squared_error: 0.0293 - val_loss: 0.0731 - val_mean_squared_error: 0.0685\n",
      "Epoch 37/50\n",
      "15575/15575 [==============================] - 72s 5ms/step - loss: 0.0332 - mean_squared_error: 0.0290 - val_loss: 0.0743 - val_mean_squared_error: 0.0701\n",
      "Epoch 38/50\n",
      "15575/15575 [==============================] - 72s 5ms/step - loss: 0.0342 - mean_squared_error: 0.0296 - val_loss: 0.0719 - val_mean_squared_error: 0.0677\n",
      "Epoch 39/50\n",
      "15575/15575 [==============================] - 72s 5ms/step - loss: 0.0330 - mean_squared_error: 0.0288 - val_loss: 0.0704 - val_mean_squared_error: 0.0663\n",
      "Epoch 40/50\n",
      "15575/15575 [==============================] - 72s 5ms/step - loss: 0.0334 - mean_squared_error: 0.0291 - val_loss: 0.0678 - val_mean_squared_error: 0.0649\n",
      "Epoch 41/50\n",
      "15575/15575 [==============================] - 73s 5ms/step - loss: 0.0321 - mean_squared_error: 0.0288 - val_loss: 0.0698 - val_mean_squared_error: 0.0663\n",
      "Epoch 42/50\n",
      "15575/15575 [==============================] - 72s 5ms/step - loss: 0.0347 - mean_squared_error: 0.0307 - val_loss: 0.0801 - val_mean_squared_error: 0.0709\n",
      "Epoch 43/50\n",
      "15575/15575 [==============================] - 72s 5ms/step - loss: 0.0308 - mean_squared_error: 0.0271 - val_loss: 0.0803 - val_mean_squared_error: 0.0762\n",
      "Epoch 44/50\n",
      "15575/15575 [==============================] - 72s 5ms/step - loss: 0.0308 - mean_squared_error: 0.0276 - val_loss: 0.0753 - val_mean_squared_error: 0.0692\n",
      "Epoch 45/50\n",
      "15575/15575 [==============================] - 72s 5ms/step - loss: 0.0317 - mean_squared_error: 0.0277 - val_loss: 0.0728 - val_mean_squared_error: 0.0689\n",
      "Epoch 46/50\n",
      "15575/15575 [==============================] - 72s 5ms/step - loss: 0.0287 - mean_squared_error: 0.0253 - val_loss: 0.0682 - val_mean_squared_error: 0.0655\n",
      "Epoch 47/50\n",
      "15575/15575 [==============================] - 72s 5ms/step - loss: 0.0310 - mean_squared_error: 0.0273 - val_loss: 0.0678 - val_mean_squared_error: 0.0647\n",
      "Epoch 48/50\n",
      "15575/15575 [==============================] - 72s 5ms/step - loss: 0.0304 - mean_squared_error: 0.0272 - val_loss: 0.0737 - val_mean_squared_error: 0.0691\n",
      "Epoch 49/50\n",
      "15575/15575 [==============================] - 72s 5ms/step - loss: 0.0294 - mean_squared_error: 0.0264 - val_loss: 0.0870 - val_mean_squared_error: 0.0841\n",
      "Epoch 50/50\n",
      "15575/15575 [==============================] - 72s 5ms/step - loss: 0.0303 - mean_squared_error: 0.0265 - val_loss: 0.0672 - val_mean_squared_error: 0.0648\n",
      "4862/4862 [==============================] - 7s 1ms/step\n",
      "model10_combine Loss = 0.049991687336\n",
      "model10_combine Test Accuracy = 0.047631814551\n",
      "[0.049991687336045497, 0.04763181455102368]\n"
     ]
    }
   ],
   "source": [
    "cvrmse_stores = []\n",
    "for train, test in kfold.split(stores, origin_y):\n",
    "    model10_stores, instore = ResNet50(input_shape=stores.shape[1:])\n",
    "    model10_roads, inroad = ResNet50(input_shape=stores.shape[1:])\n",
    "    model10_pois, in3poi = ResNet50(input_shape=stores.shape[1:])\n",
    "    \n",
    "    model10_combine = Three_ResNet(model10_stores, model10_roads, model10_pois, [instore, inroad, in3poi])\n",
    "    model10_combine.compile(optimizer='adam', loss='mse', metrics=['mse'])\n",
    "    lines10_combine = model10_combine.fit([stores[train], stores[train], stores[train]], y_data[train], epochs = 50, batch_size = 16, validation_split=0.2)\n",
    "\n",
    "    preds10_combine = model10_combine.evaluate([stores[test], stores[test], stores[test]], y_data[test])\n",
    "    print (\"model10_combine Loss = \" + str(preds10_combine[0]))\n",
    "    print (\"model10_combine Test Accuracy = \" + str(preds10_combine[1]))\n",
    "    print(preds10_combine)\n",
    "    cvrmse_stores.append(preds10_combine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cvscores = [[0.050737945057266573, 0.048019854719510535],\n",
    " [0.047062903559989253, 0.044174419010667702],\n",
    " [0.058294292038009232, 0.054615884224032879],\n",
    " [0.056042961626203765, 0.05218257700379033],\n",
    " [0.051719239743978879, 0.048474260321226398]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.22247111959947874"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sqrt(np.mean(np.asarray(cvscores)[:,1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.2212583684404309"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv2 = [[0.050971167342433954, 0.047386268105106932], [0.046705227053603866, 0.044832634777657324], [0.054852741401323381, 0.053387577191396293], [0.053468271367254933, 0.051538033399423158], [0.049991687336045497, 0.04763181455102368]]\n",
    "np.sqrt(np.mean(np.asarray(cv2)[:,1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
